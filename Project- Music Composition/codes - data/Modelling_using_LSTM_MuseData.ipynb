{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8x6ArWv2Kgv6",
    "outputId": "368f6ad7-a47c-4b00-96e7-825065640cd1"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, LSTM\n",
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "from keras.optimizers import RMSprop\n",
    "#from google.colab import drive\n",
    "import numpy as np\n",
    "from data_utils import *\n",
    "from music_utils import *\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "55DK6tUDKchp"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "with open(\"t.txt\",\"w\")as f:\n",
    "  f.write(\"hello\")\n",
    "data=pd.read_csv(\"MuseData_test_30.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "id": "XAU1Kv0CKchu",
    "outputId": "f52d2367-38e0-4ed5-93d9-ce71f802fa11"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>next_note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>55</td>\n",
       "      <td>63</td>\n",
       "      <td>72</td>\n",
       "      <td>48</td>\n",
       "      <td>63</td>\n",
       "      <td>67</td>\n",
       "      <td>46</td>\n",
       "      <td>62</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>72</td>\n",
       "      <td>43</td>\n",
       "      <td>57</td>\n",
       "      <td>67</td>\n",
       "      <td>72</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>69</td>\n",
       "      <td>74</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>48</td>\n",
       "      <td>63</td>\n",
       "      <td>67</td>\n",
       "      <td>46</td>\n",
       "      <td>62</td>\n",
       "      <td>67</td>\n",
       "      <td>45</td>\n",
       "      <td>60</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>72</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>69</td>\n",
       "      <td>74</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>62</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>46</td>\n",
       "      <td>62</td>\n",
       "      <td>67</td>\n",
       "      <td>45</td>\n",
       "      <td>60</td>\n",
       "      <td>67</td>\n",
       "      <td>72</td>\n",
       "      <td>45</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>69</td>\n",
       "      <td>74</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>62</td>\n",
       "      <td>74</td>\n",
       "      <td>43</td>\n",
       "      <td>57</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67</td>\n",
       "      <td>45</td>\n",
       "      <td>60</td>\n",
       "      <td>67</td>\n",
       "      <td>72</td>\n",
       "      <td>45</td>\n",
       "      <td>58</td>\n",
       "      <td>67</td>\n",
       "      <td>72</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>62</td>\n",
       "      <td>74</td>\n",
       "      <td>43</td>\n",
       "      <td>57</td>\n",
       "      <td>62</td>\n",
       "      <td>70</td>\n",
       "      <td>43</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67</td>\n",
       "      <td>72</td>\n",
       "      <td>45</td>\n",
       "      <td>58</td>\n",
       "      <td>67</td>\n",
       "      <td>72</td>\n",
       "      <td>45</td>\n",
       "      <td>57</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>74</td>\n",
       "      <td>43</td>\n",
       "      <td>57</td>\n",
       "      <td>62</td>\n",
       "      <td>70</td>\n",
       "      <td>43</td>\n",
       "      <td>55</td>\n",
       "      <td>62</td>\n",
       "      <td>70</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4   5   6   7   8   9    ...      21  22  23  24  25  26  \\\n",
       "0  48  55  63  72  48  63  67  46  62  67    ...      72  43  57  67  72  42   \n",
       "1  72  48  63  67  46  62  67  45  60  67    ...      67  72  42  57  69  74   \n",
       "2  67  46  62  67  45  60  67  72  45  58    ...      57  69  74  42  57  62   \n",
       "3  67  45  60  67  72  45  58  67  72  45    ...      42  57  62  74  43  57   \n",
       "4  67  72  45  58  67  72  45  57  66  72    ...      74  43  57  62  70  43   \n",
       "\n",
       "   27  28  29  next_note  \n",
       "0  57  69  74         42  \n",
       "1  42  57  62         74  \n",
       "2  74  43  57         62  \n",
       "3  62  70  43         55  \n",
       "4  55  62  70         48  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "RBHSQ8C-Kchz"
   },
   "outputs": [],
   "source": [
    "sub_sequences= data.iloc[:,:30].values\n",
    "next_steps=data.iloc[:,30].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hkbfYbf-Kch3",
    "outputId": "75a9aa8b-3f5f-4cdd-e733-044f94e96515"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (69421, 30, 88)\n"
     ]
    }
   ],
   "source": [
    "len_notes=88\n",
    "maxlen=30\n",
    "\n",
    "X = np.zeros((len(sub_sequences), maxlen, len_notes), dtype=np.uint8 )\n",
    "Y = np.zeros((len(sub_sequences), len_notes), dtype=np.uint8)\n",
    "for i, seq in enumerate(sub_sequences):\n",
    "    #print(seq)\n",
    "    for t, note in enumerate(seq):\n",
    "        X[i, t, note-21] = 1\n",
    "        Y[i, note-21] = 1\n",
    "print(\"x shape:\",np.array(X).shape)\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "0E-MiJqZKch9"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, LSTM\n",
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "from keras.optimizers import RMSprop\n",
    "#from google.colab import drive\n",
    "import numpy as np\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "S9uxH2uaKciD"
   },
   "source": [
    "char_rnn = Sequential()\n",
    "char_rnn.add(LSTM(32, input_shape=(maxlen, 88)))\n",
    "char_rnn.add(Dense(88,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "7mNiGyyNKciI"
   },
   "outputs": [],
   "source": [
    "\n",
    "#char_rnn.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01),metrics=[\"acc\"])\n",
    "#char_rnn.fit(X,Y, epochs=50, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "IPkkU3WlKciQ",
    "outputId": "2cb0936c-58bb-444b-9883-58d015f51538"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (69421, 30, 88)\n",
      "y2 shape: (30, 69421, 88)\n"
     ]
    }
   ],
   "source": [
    "## LSTM\n",
    "len_notes=88\n",
    "maxlen=30\n",
    "\n",
    "X = np.zeros((len(sub_sequences), maxlen, len_notes), dtype=np.uint8 )\n",
    "Y2 = np.zeros((maxlen, len(sub_sequences),  len_notes), dtype=np.uint8)\n",
    "for i, seq in enumerate(sub_sequences):\n",
    "    #print(seq)\n",
    "    for t, note in enumerate(seq):\n",
    "        \n",
    "\n",
    "        if t>0:\n",
    "            X[i, t, note-21] = 1\n",
    "            Y2[t-1, i, note-21] = 1\n",
    "print(\"x shape:\",np.array(X).shape)\n",
    "print(\"y2 shape:\",np.array(Y2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "fh-3KeujKciW"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, LSTM\n",
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "from keras.optimizers import RMSprop\n",
    "#from google.colab import drive\n",
    "import numpy as np\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "n_a = 64 \n",
    "n_values=88\n",
    "reshapor = Reshape((1, 88))                        # Used in Step 2.B of djmodel(), below\n",
    "LSTM_cell = LSTM(n_a,return_state=True)         # Used in Step 2.C\n",
    "densor = Dense(n_values, activation='softmax')     # Used in Step 2.D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "XUZG8MD5KciY"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# GRADED FUNCTION: djmodel\n",
    "\n",
    "def djmodel(Tx, n_a, n_values):\n",
    "    \"\"\"\n",
    "    Implement the model\n",
    "    \n",
    "    Arguments:\n",
    "    Tx -- length of the sequence in a corpus\n",
    "    n_a -- the number of activations used in our model\n",
    "    n_values -- number of unique values in the music data \n",
    "    \n",
    "    Returns:\n",
    "    model -- a keras model with the \n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input of your model with a shape \n",
    "    X = Input(shape=(Tx, n_values))\n",
    "    \n",
    "    # Define s0, initial hidden state for the decoder LSTM\n",
    "    a0 = Input(shape=(n_a,), name='a0')\n",
    "    c0 = Input(shape=(n_a,), name='c0')\n",
    "    a = a0\n",
    "    c = c0\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    # Step 1: Create empty list to append the outputs while you iterate (≈1 line)\n",
    "    outputs = []\n",
    "    \n",
    "    # Step 2: Loop\n",
    "    for t in range(Tx):\n",
    "        \n",
    "        # Step 2.A: select the \"t\"th time step vector from X. \n",
    "        x = Lambda(lambda x: X[:,t,:])(X) #Wraps arbitrary expression as a Layer object.\n",
    "        # Step 2.B: Use reshapor to reshape x to be (1, n_values) (≈1 line)\n",
    "        x =reshapor(x)    \n",
    "        # Step 2.C: Perform one step of the LSTM_cell\n",
    "        a, _, c = LSTM_cell(x, initial_state=[a, c])\n",
    "        #LSTM_cell(x, initial_state=[a, c])\n",
    "        # Step 2.D: Apply densor to the hidden state output of LSTM_Cell\n",
    "        out = densor(a)\n",
    "        # Step 2.E: add the output to \"outputs\"\n",
    "        outputs.append(out)\n",
    "        \n",
    "    # Step 3: Create model instance\n",
    "    model = Model(inputs = [X,a0,c0],outputs = outputs)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model\n",
    "model = djmodel(Tx = 30 , n_a = 64, n_values = 88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 30, 88)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_61 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 88)        0           lambda_61[0][0]                  \n",
      "                                                                 lambda_62[0][0]                  \n",
      "                                                                 lambda_63[0][0]                  \n",
      "                                                                 lambda_64[0][0]                  \n",
      "                                                                 lambda_65[0][0]                  \n",
      "                                                                 lambda_66[0][0]                  \n",
      "                                                                 lambda_67[0][0]                  \n",
      "                                                                 lambda_68[0][0]                  \n",
      "                                                                 lambda_69[0][0]                  \n",
      "                                                                 lambda_70[0][0]                  \n",
      "                                                                 lambda_71[0][0]                  \n",
      "                                                                 lambda_72[0][0]                  \n",
      "                                                                 lambda_73[0][0]                  \n",
      "                                                                 lambda_74[0][0]                  \n",
      "                                                                 lambda_75[0][0]                  \n",
      "                                                                 lambda_76[0][0]                  \n",
      "                                                                 lambda_77[0][0]                  \n",
      "                                                                 lambda_78[0][0]                  \n",
      "                                                                 lambda_79[0][0]                  \n",
      "                                                                 lambda_80[0][0]                  \n",
      "                                                                 lambda_81[0][0]                  \n",
      "                                                                 lambda_82[0][0]                  \n",
      "                                                                 lambda_83[0][0]                  \n",
      "                                                                 lambda_84[0][0]                  \n",
      "                                                                 lambda_85[0][0]                  \n",
      "                                                                 lambda_86[0][0]                  \n",
      "                                                                 lambda_87[0][0]                  \n",
      "                                                                 lambda_88[0][0]                  \n",
      "                                                                 lambda_89[0][0]                  \n",
      "                                                                 lambda_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "a0 (InputLayer)                 (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_62 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 64), (None,  39168       reshape_2[0][0]                  \n",
      "                                                                 a0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 reshape_2[1][0]                  \n",
      "                                                                 lstm_2[0][0]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "                                                                 reshape_2[2][0]                  \n",
      "                                                                 lstm_2[1][0]                     \n",
      "                                                                 lstm_2[1][2]                     \n",
      "                                                                 reshape_2[3][0]                  \n",
      "                                                                 lstm_2[2][0]                     \n",
      "                                                                 lstm_2[2][2]                     \n",
      "                                                                 reshape_2[4][0]                  \n",
      "                                                                 lstm_2[3][0]                     \n",
      "                                                                 lstm_2[3][2]                     \n",
      "                                                                 reshape_2[5][0]                  \n",
      "                                                                 lstm_2[4][0]                     \n",
      "                                                                 lstm_2[4][2]                     \n",
      "                                                                 reshape_2[6][0]                  \n",
      "                                                                 lstm_2[5][0]                     \n",
      "                                                                 lstm_2[5][2]                     \n",
      "                                                                 reshape_2[7][0]                  \n",
      "                                                                 lstm_2[6][0]                     \n",
      "                                                                 lstm_2[6][2]                     \n",
      "                                                                 reshape_2[8][0]                  \n",
      "                                                                 lstm_2[7][0]                     \n",
      "                                                                 lstm_2[7][2]                     \n",
      "                                                                 reshape_2[9][0]                  \n",
      "                                                                 lstm_2[8][0]                     \n",
      "                                                                 lstm_2[8][2]                     \n",
      "                                                                 reshape_2[10][0]                 \n",
      "                                                                 lstm_2[9][0]                     \n",
      "                                                                 lstm_2[9][2]                     \n",
      "                                                                 reshape_2[11][0]                 \n",
      "                                                                 lstm_2[10][0]                    \n",
      "                                                                 lstm_2[10][2]                    \n",
      "                                                                 reshape_2[12][0]                 \n",
      "                                                                 lstm_2[11][0]                    \n",
      "                                                                 lstm_2[11][2]                    \n",
      "                                                                 reshape_2[13][0]                 \n",
      "                                                                 lstm_2[12][0]                    \n",
      "                                                                 lstm_2[12][2]                    \n",
      "                                                                 reshape_2[14][0]                 \n",
      "                                                                 lstm_2[13][0]                    \n",
      "                                                                 lstm_2[13][2]                    \n",
      "                                                                 reshape_2[15][0]                 \n",
      "                                                                 lstm_2[14][0]                    \n",
      "                                                                 lstm_2[14][2]                    \n",
      "                                                                 reshape_2[16][0]                 \n",
      "                                                                 lstm_2[15][0]                    \n",
      "                                                                 lstm_2[15][2]                    \n",
      "                                                                 reshape_2[17][0]                 \n",
      "                                                                 lstm_2[16][0]                    \n",
      "                                                                 lstm_2[16][2]                    \n",
      "                                                                 reshape_2[18][0]                 \n",
      "                                                                 lstm_2[17][0]                    \n",
      "                                                                 lstm_2[17][2]                    \n",
      "                                                                 reshape_2[19][0]                 \n",
      "                                                                 lstm_2[18][0]                    \n",
      "                                                                 lstm_2[18][2]                    \n",
      "                                                                 reshape_2[20][0]                 \n",
      "                                                                 lstm_2[19][0]                    \n",
      "                                                                 lstm_2[19][2]                    \n",
      "                                                                 reshape_2[21][0]                 \n",
      "                                                                 lstm_2[20][0]                    \n",
      "                                                                 lstm_2[20][2]                    \n",
      "                                                                 reshape_2[22][0]                 \n",
      "                                                                 lstm_2[21][0]                    \n",
      "                                                                 lstm_2[21][2]                    \n",
      "                                                                 reshape_2[23][0]                 \n",
      "                                                                 lstm_2[22][0]                    \n",
      "                                                                 lstm_2[22][2]                    \n",
      "                                                                 reshape_2[24][0]                 \n",
      "                                                                 lstm_2[23][0]                    \n",
      "                                                                 lstm_2[23][2]                    \n",
      "                                                                 reshape_2[25][0]                 \n",
      "                                                                 lstm_2[24][0]                    \n",
      "                                                                 lstm_2[24][2]                    \n",
      "                                                                 reshape_2[26][0]                 \n",
      "                                                                 lstm_2[25][0]                    \n",
      "                                                                 lstm_2[25][2]                    \n",
      "                                                                 reshape_2[27][0]                 \n",
      "                                                                 lstm_2[26][0]                    \n",
      "                                                                 lstm_2[26][2]                    \n",
      "                                                                 reshape_2[28][0]                 \n",
      "                                                                 lstm_2[27][0]                    \n",
      "                                                                 lstm_2[27][2]                    \n",
      "                                                                 reshape_2[29][0]                 \n",
      "                                                                 lstm_2[28][0]                    \n",
      "                                                                 lstm_2[28][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_63 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_64 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_65 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_66 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_67 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_68 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_69 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_70 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_71 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_72 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_73 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_74 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_75 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_76 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_77 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_78 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_79 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_80 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_81 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_82 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_83 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_84 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_85 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_86 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_87 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_88 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_89 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_90 (Lambda)              (None, 88)           0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 88)           5720        lstm_2[0][0]                     \n",
      "                                                                 lstm_2[1][0]                     \n",
      "                                                                 lstm_2[2][0]                     \n",
      "                                                                 lstm_2[3][0]                     \n",
      "                                                                 lstm_2[4][0]                     \n",
      "                                                                 lstm_2[5][0]                     \n",
      "                                                                 lstm_2[6][0]                     \n",
      "                                                                 lstm_2[7][0]                     \n",
      "                                                                 lstm_2[8][0]                     \n",
      "                                                                 lstm_2[9][0]                     \n",
      "                                                                 lstm_2[10][0]                    \n",
      "                                                                 lstm_2[11][0]                    \n",
      "                                                                 lstm_2[12][0]                    \n",
      "                                                                 lstm_2[13][0]                    \n",
      "                                                                 lstm_2[14][0]                    \n",
      "                                                                 lstm_2[15][0]                    \n",
      "                                                                 lstm_2[16][0]                    \n",
      "                                                                 lstm_2[17][0]                    \n",
      "                                                                 lstm_2[18][0]                    \n",
      "                                                                 lstm_2[19][0]                    \n",
      "                                                                 lstm_2[20][0]                    \n",
      "                                                                 lstm_2[21][0]                    \n",
      "                                                                 lstm_2[22][0]                    \n",
      "                                                                 lstm_2[23][0]                    \n",
      "                                                                 lstm_2[24][0]                    \n",
      "                                                                 lstm_2[25][0]                    \n",
      "                                                                 lstm_2[26][0]                    \n",
      "                                                                 lstm_2[27][0]                    \n",
      "                                                                 lstm_2[28][0]                    \n",
      "                                                                 lstm_2[29][0]                    \n",
      "==================================================================================================\n",
      "Total params: 44,888\n",
      "Trainable params: 44,888\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "KwGu42rHKcic",
    "outputId": "38f529ef-4e13-4106-b06b-69846603a2e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "69421/69421 [==============================] - 99s 1ms/step - loss: 60.1956 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0604 - dense_2_acc_1: 0.2395 - dense_2_acc_2: 0.2839 - dense_2_acc_3: 0.3220 - dense_2_acc_4: 0.3763 - dense_2_acc_5: 0.4133 - dense_2_acc_6: 0.4404 - dense_2_acc_7: 0.4583 - dense_2_acc_8: 0.4676 - dense_2_acc_9: 0.4779 - dense_2_acc_10: 0.4866 - dense_2_acc_11: 0.4900 - dense_2_acc_12: 0.4903 - dense_2_acc_13: 0.4937 - dense_2_acc_14: 0.4910 - dense_2_acc_15: 0.4925 - dense_2_acc_16: 0.4953 - dense_2_acc_17: 0.4929 - dense_2_acc_18: 0.4934 - dense_2_acc_19: 0.4968 - dense_2_acc_20: 0.4949 - dense_2_acc_21: 0.4946 - dense_2_acc_22: 0.4966 - dense_2_acc_23: 0.4950 - dense_2_acc_24: 0.4933 - dense_2_acc_25: 0.4952 - dense_2_acc_26: 0.4941 - dense_2_acc_27: 0.4932 - dense_2_acc_28: 0.4958 - dense_2_acc_29: 0.0000e+00\n",
      "Epoch 2/20\n",
      "69421/69421 [==============================] - 75s 1ms/step - loss: 54.0141 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0616 - dense_2_acc_1: 0.2442 - dense_2_acc_2: 0.2910 - dense_2_acc_3: 0.3382 - dense_2_acc_4: 0.4035 - dense_2_acc_5: 0.4505 - dense_2_acc_6: 0.4815 - dense_2_acc_7: 0.5078 - dense_2_acc_8: 0.5221 - dense_2_acc_9: 0.5368 - dense_2_acc_10: 0.5483 - dense_2_acc_11: 0.5514 - dense_2_acc_12: 0.5527 - dense_2_acc_13: 0.5591 - dense_2_acc_14: 0.5578 - dense_2_acc_15: 0.5575 - dense_2_acc_16: 0.5628 - dense_2_acc_17: 0.5599 - dense_2_acc_18: 0.5587 - dense_2_acc_19: 0.5635 - dense_2_acc_20: 0.5627 - dense_2_acc_21: 0.5611 - dense_2_acc_22: 0.5641 - dense_2_acc_23: 0.5627 - dense_2_acc_24: 0.5598 - dense_2_acc_25: 0.5643 - dense_2_acc_26: 0.5623 - dense_2_acc_27: 0.5586 - dense_2_acc_28: 0.5636 - dense_2_acc_29: 0.0000e+00\n",
      "Epoch 3/20\n",
      "69421/69421 [==============================] - 75s 1ms/step - loss: 52.9776 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0625 - dense_2_acc_1: 0.2435 - dense_2_acc_2: 0.2924 - dense_2_acc_3: 0.3415 - dense_2_acc_4: 0.4060 - dense_2_acc_5: 0.4551 - dense_2_acc_6: 0.4861 - dense_2_acc_7: 0.5153 - dense_2_acc_8: 0.5300 - dense_2_acc_9: 0.5446 - dense_2_acc_10: 0.5575 - dense_2_acc_11: 0.5602 - dense_2_acc_12: 0.5640 - dense_2_acc_13: 0.5699 - dense_2_acc_14: 0.5697 - dense_2_acc_15: 0.5692 - dense_2_acc_16: 0.5737 - dense_2_acc_17: 0.5732 - dense_2_acc_18: 0.5724 - dense_2_acc_19: 0.5749 - dense_2_acc_20: 0.5723 - dense_2_acc_21: 0.5730 - dense_2_acc_22: 0.5768 - dense_2_acc_23: 0.5743 - dense_2_acc_24: 0.5727 - dense_2_acc_25: 0.5760 - dense_2_acc_26: 0.5738 - dense_2_acc_27: 0.5722 - dense_2_acc_28: 0.5765 - dense_2_acc_29: 0.0000e+00TA: 1:05 - loss: 53.3458 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0662 - dense_2_acc_1: 0.2477 - dense_2_acc_2: 0.2832 - dense_2_acc_3: 0.3377 - dense_2_acc_4: 0.4012 - dense_2_acc_5: 0.4469 - dense_2_acc_6: 0.4938 - dense_2 - ETA: 44s - loss: 53.2789 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0624 - dense_2_acc_1: 0.2472 - dense_2_acc_2: 0.2939 - dense_2_acc_3: 0.3398 - dense_2_acc_4: 0.4040 - dense_2_acc_5: 0.4563 - dense_2_acc_6: 0.4872 - dense_2_acc_7: 0.5119 - dense_2_acc_8: 0.5265 - dense_2_acc_9: 0.5412 - dense_2_acc_10: 0.5517 - dense_2_acc_11: 0.5565 - dense_2_acc_12: 0.5628 - dense_2_acc_13: 0.5675 - dense_2_acc_14: 0.5695 - dense_2_acc_15: 0.5660 - dense_2_acc_16: 0.5664 - dense_2_acc_17: 0.5729 - dense_2_acc_18: 0.5693 - dense_2_acc_19: 0.5711 - dense_2_acc_20: 0.5692 - dense_2_acc_21 - ETA: 37s - loss: 53.1783 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0620 - dense_2_acc_1: 0.2446 - dense_2_acc_2: 0.2952 - dense_2_acc_3: 0.3423 - dense_2_acc_4: 0.4049 - dense_2_acc_5: 0.4547 - dense_2_acc_6: 0.4866 - dense_2_acc_7: 0.5135 - dense_2_acc_8: 0.5263 - dense_2_acc_9: 0.5428 - dense_2_acc_10: 0.5530 - dense_2_acc_11: 0.5577 - dense_2_acc_12: 0.5629 - dense_2_acc_13: 0.56 - ETA: 24s - loss: 53.0784 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0612 - dense_2_acc_1: 0.2442 - dense_2_acc_2: 0.2934 - dense_2_acc_3: 0.3421 - dense_2_acc_4: 0.4055 - dense_2_acc_5: \n",
      "Epoch 4/20\n",
      "69421/69421 [==============================] - 74s 1ms/step - loss: 52.4671 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0632 - dense_2_acc_1: 0.2437 - dense_2_acc_2: 0.2941 - dense_2_acc_3: 0.3420 - dense_2_acc_4: 0.4079 - dense_2_acc_5: 0.4578 - dense_2_acc_6: 0.4904 - dense_2_acc_7: 0.5184 - dense_2_acc_8: 0.5343 - dense_2_acc_9: 0.5490 - dense_2_acc_10: 0.5619 - dense_2_acc_11: 0.5645 - dense_2_acc_12: 0.5696 - dense_2_acc_13: 0.5747 - dense_2_acc_14: 0.5749 - dense_2_acc_15: 0.5754 - dense_2_acc_16: 0.5798 - dense_2_acc_17: 0.5776 - dense_2_acc_18: 0.5777 - dense_2_acc_19: 0.5811 - dense_2_acc_20: 0.5798 - dense_2_acc_21: 0.5783 - dense_2_acc_22: 0.5835 - dense_2_acc_23: 0.5804 - dense_2_acc_24: 0.5786 - dense_2_acc_25: 0.5835 - dense_2_acc_26: 0.5799 - dense_2_acc_27: 0.5793 - dense_2_acc_28: 0.5818 - dense_2_acc_29: 0.0000e+00: 20s - loss: 52.5279 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0637 - dense_2_acc_1: 0.2434 - dense_2_acc_2: 0.2920 - dense_2_acc_3: 0.3403 - dense_2_acc_4: 0.4070 - dense_2_acc_5: 0.4587 - dense_2_acc_6: 0.4894 - dense_2_acc_7: 0.5184 - dense_2_acc_8: 0.5355 - dense_2_acc_9: 0.5480 - dense_2_acc_10: 0.5598 - dense_2_acc_11: 0.5642 -\n",
      "Epoch 5/20\n",
      "69421/69421 [==============================] - 76s 1ms/step - loss: 52.1509 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0625 - dense_2_acc_1: 0.2430 - dense_2_acc_2: 0.2945 - dense_2_acc_3: 0.3429 - dense_2_acc_4: 0.4090 - dense_2_acc_5: 0.4577 - dense_2_acc_6: 0.4922 - dense_2_acc_7: 0.5205 - dense_2_acc_8: 0.5364 - dense_2_acc_9: 0.5521 - dense_2_acc_10: 0.5657 - dense_2_acc_11: 0.5679 - dense_2_acc_12: 0.5721 - dense_2_acc_13: 0.5781 - dense_2_acc_14: 0.5781 - dense_2_acc_15: 0.5789 - dense_2_acc_16: 0.5834 - dense_2_acc_17: 0.5815 - dense_2_acc_18: 0.5819 - dense_2_acc_19: 0.5848 - dense_2_acc_20: 0.5830 - dense_2_acc_21: 0.5836 - dense_2_acc_22: 0.5874 - dense_2_acc_23: 0.5838 - dense_2_acc_24: 0.5824 - dense_2_acc_25: 0.5865 - dense_2_acc_26: 0.5831 - dense_2_acc_27: 0.5823 - dense_2_acc_28: 0.5852 - dense_2_acc_29: 0.0000e+00: 12s - loss: 52.1510 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0631 - dense_2_acc_1: 0.2433 - dense_2_acc_2: 0.2938 - dense_2_acc_3: 0.3440 - dense_2_acc_4: 0.4095 - dense_2_acc_5: 0.4571 - dense_2_acc_6: 0.4924 - dense_2_acc_7: 0.5194 - dense_2_acc_8: 0.5353 - dense_2_acc_9: 0.5525 - dense_2_acc_10: 0.5660 - dense_2_acc_11: 0.5695 - dense_2_acc_12: 0.5721 - dense_2_acc_13: 0.5779 - dense_2_acc_14: 0.5782 - dense_2_acc_15: 0.5783 - dense_2_acc_16: 0.5826 - dense_2_acc_17: 0.5812 - dense_2_acc_18: 0.5804 - dense_2_acc_19: 0.5837 - dense_2_acc_20: 0.5828 - dense_2_acc_21: 0.5\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69421/69421 [==============================] - 78s 1ms/step - loss: 51.9263 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0640 - dense_2_acc_1: 0.2432 - dense_2_acc_2: 0.2943 - dense_2_acc_3: 0.3437 - dense_2_acc_4: 0.4105 - dense_2_acc_5: 0.4584 - dense_2_acc_6: 0.4935 - dense_2_acc_7: 0.5230 - dense_2_acc_8: 0.5375 - dense_2_acc_9: 0.5532 - dense_2_acc_10: 0.5663 - dense_2_acc_11: 0.5706 - dense_2_acc_12: 0.5742 - dense_2_acc_13: 0.5811 - dense_2_acc_14: 0.5794 - dense_2_acc_15: 0.5812 - dense_2_acc_16: 0.5871 - dense_2_acc_17: 0.5834 - dense_2_acc_18: 0.5836 - dense_2_acc_19: 0.5884 - dense_2_acc_20: 0.5856 - dense_2_acc_21: 0.5852 - dense_2_acc_22: 0.5886 - dense_2_acc_23: 0.5859 - dense_2_acc_24: 0.5853 - dense_2_acc_25: 0.5892 - dense_2_acc_26: 0.5862 - dense_2_acc_27: 0.5849 - dense_2_acc_28: 0.5890 - dense_2_acc_29: 0.0000e+00TA: 1:13 - loss: 51.7966 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0615 - dense_2_acc_1: 0.2426 - dense_2_acc_2: 0.3249 - dense_2_acc_3: 0.3407 - dense_2_acc_4: 0.4069 - dense_2_acc_5: 0.4486 - dense_2_acc_6: 0.5024 - dense_2_acc_7: 0.5239 - dense_2_acc_8: 0.5195 - dense_2_acc_9: 0.5413 - dense_2_acc_10: 0.5635 - dense_2_acc_11: 0.5615 - dense_2_acc_12: 0.5679 - dense_2_acc_13: 0.5642 - dense_2_acc_14: 0.5823 - dense_2_acc_15: 0.5810 - dense_2_acc_16: 0.5806 - dense_2_acc_17: 0.5729 - dense_2_acc_18: 0.5803 - dense_2_acc_19: 0.5954 - dense_2_acc_20: 0.5867 - dense_2_acc_21: 0.5830 - dense_2_acc_22: 0.5877 - dense_2_acc_23: 0.6032 - dense_2_acc_24: 0.5837 - dense_2_acc - ETA: 1:02 - loss: 51.7768 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0627 - dense_2_acc_1: 0.2432 - dense_2_acc_2: 0.3031 - dense_2_acc_3: 0.3505 - dense_2_acc_4: 0.4111 - dense_2_acc_5: 0.4586 - dense_2_acc_6: 0.4983 - dense_2_acc_7: 0.5238 - dense_2_acc_8: 0.5364 - dense_2_acc_9: 0.5482 - dense_2_acc_10: 0.5715 - dense_2_acc_11: 0.5664 - dense_2_acc_12: 0.5780 - dense_2_acc_13: 0.5809 - dense_2_acc_14: 0.5811 - dense_2_acc_15: 0.5823 - dense_2_acc_16: 0.5843 - dense_2_acc_17: 0.5806 - dense_2_acc_18: 0.5824 - dense_2_acc_19: 0.5865 - dense_2_acc_20: 0.5897 - dense_2_acc_21: 0.5879 - dense_2_acc_22: 0.5943 - dense_2_acc_23: 0.5940 - dense_2_acc_24: 0.5843 - dense_2_acc_25: 0.5976 - dense_2_acc_26: 0.5892 - dense_2_acc_27: 0.5877 - dense_2_acc_28: 0.5939 - de - ETA: 1:00 - loss: 51.8252 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0626 - dense_2_acc_1: 0.2422 - dense_2_acc_2: 0.3016 - dense_2_acc_3: 0.3474 - dense_2_acc_4: 0.4101 - dense_2_acc_5: 0.4591 - dense_2_acc_6: 0.4995 - dense_2_acc_7: 0.5238 - dense_2_acc_8: 0.5368 - dense_2_acc_9: 0.5481 - dense_2_acc_10: 0.5699 - dense_2_acc_11: 0.5670 - dense_2_acc_12: 0.5788 - dense_2_acc_13: 0.5809 - dense_2_acc_14: 0.5820 - dense_2_acc_15: 0.5827 - dense_2_acc - ETA: 48s - loss: 51.9709 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0623 - dense_2_acc_1: 0.2438 - dense_2_acc_2: 0.2974 - dense_2_acc_3: 0.3488 - dense_2_acc_4: 0.4095 - dense_2_acc_5: 0.4600 - dense_2_acc_6: 0.4938 - dense_2_acc_7: 0.5224 - dense_2_acc_8: 0.5356 - dense_2_acc_9: 0.5501 - dense_2_acc_10: 0.5671 - dense_2_acc_11: 0.5711 - dense_2_acc_12: 0.5752 - dense_2_acc_13: 0.5773 - dense_2_acc_14: 0.5782 - dense_2_acc_15: 0.5813 - dense_2_acc_16: 0.5832 - dense_2_acc_17: 0.5831 - dense_2_acc_18: 0.5839 - dense_2_acc_19: 0.5852 - dense_2_acc_20: 0.5881 - dense_2_acc_21: 0.5837 - dense_2_acc_2 - ETA: 17s - loss: 51.9390 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0636 - dense_2_acc_1: 0.2428 - dense_2_acc_2: 0.2951 - dense_2_acc_3: 0.3441 - dense_2_acc_4: 0.4113 - dense_2_acc_5: 0.4584 - dense_2_acc_6: 0.4923 - dense_2_acc_7: 0.5245 - dense_2_acc_8: 0.5373 - dense_2_acc_9: 0.5524 - dense_2_acc_10: 0.5665 - dense_2_acc_11: 0.5714 - dense_2_acc_12: 0.5746 - dense_2_acc_13: 0.5796 - dense_2_acc_14: 0.5778 - dense_2_acc_15: 0.5803 - dense_2_acc_16: 0.5865 - dense_2_acc_17: 0.5850 - dense_2_acc_18: 0.5838 - dense_2_acc_1 - ETA: 9s - loss: 51.9413 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0640 - dense_2_acc_1: 0.2421 - dense_2_acc_2: 0.2947 - dense_2_acc_3: 0.3440 - dense_2_acc_4: 0.4109 - dense_2_acc_5: 0.4588 - dense_2_acc_6: 0.4934 - dense_2_acc_7: 0.5241 - dense_2_acc_8: 0.5372 - dense_2_acc_9: 0.5535 - dense_2_acc_10: 0.5657 - dense_2_acc_11: 0.5713 - dense_2_acc_12: 0.5740 - dense_2_acc_13: 0.5797 - dense_2_acc_14: 0.5787 - dense_2_acc_15: 0.5798 - dense_2_acc_16: 0.5864 - dense_2_acc_17: 0.5839 - dense_2_acc_18: 0.5840 - dense_2_acc_19: 0.5886 - dense_2_acc_20: 0.5859 - dense_2_acc_21: 0.5849 - dense_2_acc_22: 0.5896 - dense_2_acc_23: 0.5866 -\n",
      "Epoch 7/20\n",
      "69421/69421 [==============================] - 77s 1ms/step - loss: 51.7559 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0632 - dense_2_acc_1: 0.2438 - dense_2_acc_2: 0.2949 - dense_2_acc_3: 0.3436 - dense_2_acc_4: 0.4112 - dense_2_acc_5: 0.4594 - dense_2_acc_6: 0.4947 - dense_2_acc_7: 0.5238 - dense_2_acc_8: 0.5384 - dense_2_acc_9: 0.5555 - dense_2_acc_10: 0.5683 - dense_2_acc_11: 0.5719 - dense_2_acc_12: 0.5757 - dense_2_acc_13: 0.5831 - dense_2_acc_14: 0.5819 - dense_2_acc_15: 0.5825 - dense_2_acc_16: 0.5885 - dense_2_acc_17: 0.5847 - dense_2_acc_18: 0.5862 - dense_2_acc_19: 0.5895 - dense_2_acc_20: 0.5866 - dense_2_acc_21: 0.5872 - dense_2_acc_22: 0.5916 - dense_2_acc_23: 0.5873 - dense_2_acc_24: 0.5873 - dense_2_acc_25: 0.5903 - dense_2_acc_26: 0.5878 - dense_2_acc_27: 0.5866 - dense_2_acc_28: 0.5909 - dense_2_acc_29: 1.4405e-05TA: 1:06 - loss: 51.8875 - dense_2_los - ETA: 12s - loss: 51.7961 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0625 - dense_2_acc_1: 0.2420 - dense_2_acc_2: 0.2951 - dense_2_acc_3: 0.3432 - dense_2_acc_4: 0.4114 - dense_2_acc_5: 0.4597 - dense_2_acc_6: 0.4950 - dense_2_acc_7: 0.5238 - dense_2_acc_8: 0.5387 - dense_2_acc_9: 0.5558 - dense_2_acc_10: 0.5678 - dense_2_acc_11: 0.5723 - dense_2_acc_12: 0.5753 - dense_2_acc_13: 0.5827 - dense_2_acc_14: 0.5815 - dense_2_acc_15: 0.5819 - dense_2_acc_16: 0.5867 - dense_2_acc_17: 0.5823 - dense_2_acc_18: 0.5857 - dense_2_acc_19: 0.5888 - dense_2_acc_20: 0.5866 - dense_2_\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69421/69421 [==============================] - 76s 1ms/step - loss: 51.6222 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0643 - dense_2_acc_1: 0.2429 - dense_2_acc_2: 0.2952 - dense_2_acc_3: 0.3441 - dense_2_acc_4: 0.4114 - dense_2_acc_5: 0.4607 - dense_2_acc_6: 0.4952 - dense_2_acc_7: 0.5247 - dense_2_acc_8: 0.5398 - dense_2_acc_9: 0.5549 - dense_2_acc_10: 0.5694 - dense_2_acc_11: 0.5727 - dense_2_acc_12: 0.5767 - dense_2_acc_13: 0.5827 - dense_2_acc_14: 0.5826 - dense_2_acc_15: 0.5839 - dense_2_acc_16: 0.5893 - dense_2_acc_17: 0.5870 - dense_2_acc_18: 0.5873 - dense_2_acc_19: 0.5911 - dense_2_acc_20: 0.5877 - dense_2_acc_21: 0.5890 - dense_2_acc_22: 0.5925 - dense_2_acc_23: 0.5888 - dense_2_acc_24: 0.5886 - dense_2_acc_25: 0.5935 - dense_2_acc_26: 0.5890 - dense_2_acc_27: 0.5876 - dense_2_acc_28: 0.5919 - dense_2_acc_29: 1.4405e-05: 42s - loss: 51.6561 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0638 - dense_2_acc_1: 0.2435 - dense_2_acc_2: 0.2959 - dense_2_acc_3: 0.3446 - dense_2_acc_4: 0.4139 - dense_2_acc_5: 0.4627 - dense_2_acc_6: 0.4928 - dense_2_acc_7: 0.5252 - dense_2_acc_8: 0.5401 - dense_2_acc_9: 0.5528 - dense_2_acc_10: 0.5669 - dense_2_acc_11: 0.5717 - dense_2_acc_12: 0.5772 - dense_2_acc_13: 0.5817 - dense_2_acc_14: 0.5810 - dense_2_acc_15: 0.5864 - dense_2_acc_16: 0.5871 - dense_2_acc_17: 0.5862 - dense_2_acc_18: 0.5873 - dense_2_acc_19: 0.5914 - \n",
      "Epoch 9/20\n",
      "69421/69421 [==============================] - 77s 1ms/step - loss: 51.5117 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0630 - dense_2_acc_1: 0.2434 - dense_2_acc_2: 0.2951 - dense_2_acc_3: 0.3445 - dense_2_acc_4: 0.4119 - dense_2_acc_5: 0.4602 - dense_2_acc_6: 0.4959 - dense_2_acc_7: 0.5244 - dense_2_acc_8: 0.5413 - dense_2_acc_9: 0.5571 - dense_2_acc_10: 0.5706 - dense_2_acc_11: 0.5740 - dense_2_acc_12: 0.5778 - dense_2_acc_13: 0.5847 - dense_2_acc_14: 0.5842 - dense_2_acc_15: 0.5861 - dense_2_acc_16: 0.5908 - dense_2_acc_17: 0.5885 - dense_2_acc_18: 0.5887 - dense_2_acc_19: 0.5926 - dense_2_acc_20: 0.5898 - dense_2_acc_21: 0.5898 - dense_2_acc_22: 0.5943 - dense_2_acc_23: 0.5899 - dense_2_acc_24: 0.5906 - dense_2_acc_25: 0.5941 - dense_2_acc_26: 0.5907 - dense_2_acc_27: 0.5895 - dense_2_acc_28: 0.5929 - dense_2_acc_29: 1.4405e-05: 10s - loss: 51.5470 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0623 - dense_2_acc_1: 0.2435 - dense_2_acc_2: 0.2946 - dense_2_acc_3: 0.3442 - dense_2_acc_4: 0.4122 - dense_2_acc_5: 0.4609 - dense_2_acc_6: 0.4960 - dense_2_acc_7: 0.5234 - dense_2_acc_8: 0.5402 - dense_2_acc_9: 0.5580 - dense_2_acc_10: 0.5699 - dense_2_acc_11: 0.5731 - dense_2_acc_12: 0.5781 - dense_2_acc_13: 0.5841 - dense_2_acc_14: 0.5835 - dense_2_acc_15: 0.5848 - dense_2_acc_16: 0.5902 - dense_2_acc_17: 0.5882 - dense_2_acc_18: 0.5872 - dense_2_acc_19: 0.5919 - dense_2_acc_20: 0.5905 - dense_2_acc_21: 0.5889 - dense_2_acc_22: 0.5929 - dense_2_acc_23: 0.5899 - dense_2_acc_24: 0.5898 - dense_2_acc_25: 0.5940 - dense_ - ETA: 3s - loss: 51.5316 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0625 - dense_2_acc_1: 0.2434 - dense_2_acc_2: 0.2948 - dense_2_acc_3: 0.3444 - dense_2_acc_4: 0.4116 - dense_2_acc_5: 0.4605 - dense_2_acc_6: 0.4957 - dense_2_acc_7: 0.5244 - dense_2_acc_8: 0.5414 - dense_2_acc_9: 0.5580 - dense_2_acc_10: 0.5703 - dense_2_acc_11: 0.5737 - dense_2_acc_12: 0.5783 - dense_2_acc_13: 0.5847 - dense_2_acc_14: 0.5840 - dense_2_acc_15: 0.5854 - dense_2_acc_16: 0.5903 - dense_2_acc_17: 0.5883 - dense_2_acc_18: 0.5882 - dense_2_acc_19: 0.5924 - dense_2_acc_20: 0.5900 - dense_2_acc_21: 0.5892 - dense_2_acc_22: 0.5932 - dense_2_acc_23: 0.5900 - dense_2_acc_24: 0.5903 - dense_2_acc_25: 0.5941 - dense_2_acc_26: 0.5905 - dense_2_acc_27: 0.5894 -\n",
      "Epoch 10/20\n",
      "69421/69421 [==============================] - 74s 1ms/step - loss: 51.4183 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0643 - dense_2_acc_1: 0.2431 - dense_2_acc_2: 0.2954 - dense_2_acc_3: 0.3446 - dense_2_acc_4: 0.4118 - dense_2_acc_5: 0.4610 - dense_2_acc_6: 0.4968 - dense_2_acc_7: 0.5252 - dense_2_acc_8: 0.5410 - dense_2_acc_9: 0.5569 - dense_2_acc_10: 0.5703 - dense_2_acc_11: 0.5739 - dense_2_acc_12: 0.5786 - dense_2_acc_13: 0.5855 - dense_2_acc_14: 0.5848 - dense_2_acc_15: 0.5866 - dense_2_acc_16: 0.5913 - dense_2_acc_17: 0.5887 - dense_2_acc_18: 0.5899 - dense_2_acc_19: 0.5929 - dense_2_acc_20: 0.5902 - dense_2_acc_21: 0.5907 - dense_2_acc_22: 0.5955 - dense_2_acc_23: 0.5899 - dense_2_acc_24: 0.5906 - dense_2_acc_25: 0.5958 - dense_2_acc_26: 0.5907 - dense_2_acc_27: 0.5902 - dense_2_acc_28: 0.5943 - dense_2_acc_29: 1.4405e-05: 28s - loss: 51.3274 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0643 - dense_2_acc_1: 0.2435 - dense_2_acc_2: 0.2926 - dense_2_acc_3: 0.3455 - dense_2_acc_4: 0.4116 - dense_2_acc_5: 0.4602 - dense_2_acc_6: 0.4984 - dense_2_acc_7: 0.5262 - dense_2_acc_8: 0.5411 - dense_2_acc_9: 0.5585 - dense_2_acc_10: 0.5712 - dense_2_acc_11: 0.5771 - dense_2_acc_12: 0.5809 - dense_2_acc_13: 0.5846 - dense_2_acc_14: 0.5870 - dense_2_acc_15: 0.5864 - dense_2_acc_16: 0.5925 - dense_2_acc_17: 0.5886 - dense_2_acc_18: 0.5907 - dense_2_acc_19: 0.5961 - dense_2_acc_20: 0.5911 - dense_2_acc_21: 0.5900 - dense_2_acc_22: 0.5999 - dense_2_acc_23: 0.5909 - dense_2_acc_24: 0.5924 - dense_2_acc_25: 0.5978 - dense_2_acc_26: 0.5901 - dense_2_acc_27: 0.5904 - dense_2_acc_28: 0.5937 -  - ETA: 27s - loss: 51.3264 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0641 - dense_2_acc_1: 0.2433 - dense_2_acc_2: 0.2928 - dense_2_acc_3: 0.3459 - dense_2_acc_4: 0.4119 - dense_2_acc_5: 0.4602 - ETA: 5s - loss: 51.4156 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0644 - dense_2_acc_1: 0.2432 - dense_2_acc_2: 0.2954 - dense_2_acc_3: 0.3449 - dense_2_acc_4: 0.4122 - dense_2_acc_5: 0.4608 - dense_2_acc_6: 0.4970 - dense_2_acc_7: 0.5256 - dense_2_acc_8: 0.5410 - dense_2_acc_9: 0.5567 - dense_2_acc_10: 0.5708 - dense_2_acc_11: 0.5742 - dense_2_acc_12: 0.5787 - dense_2_acc_13: 0.5852 - dense_2_acc_14: 0.5843 - dense_2_acc_15: 0.5869 - dense_2_acc_16: 0.5911 - dense_2_acc_17: 0.5882 - dense_2_acc_18: 0.5900 - dense_2_acc_19: 0.5927 - dense_2_acc_20: 0.5903 - dense_2_acc_21: 0.5911 - dense_2_acc_22: 0.5968 - dense_2_acc_23: 0.5892 - dense_2_acc_24: 0.5901 - dense_2_acc_25: 0.5958 - dense_2_acc_26: 0.5904 - dense_2_acc_27: 0.5904 - dense_2_acc_28: 0.5937 - dense_2_acc_29: 1. - ETA: 4s - loss: 51.4215 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0643 - dense_2_acc_1: 0.2430 - dense_2_acc_2: 0.2956 - dense_2_acc_3: 0.3449 - dense_2_acc_4: 0.4121 - dense_2_acc_5: 0.4610 - dense_2_acc_6: 0.4971 - dense_2_acc_7: 0.5254 - dense_2_acc_8: 0.5412 - dense_2_acc_9: 0.5570 - dense_2_acc_10: 0.5706 - dense_2_acc_11: 0.5741 - dense_2_acc_12: 0.5785 - dense_2_acc_13: 0.5850 - dense_2_acc_14: 0.5845 - dense_2_acc_15: 0.5866 - dense_2_acc_16: 0.5912 - dense_2_acc_17: 0.5883 - dense_2_acc_18: 0.5898 - dense_2_acc_19: 0.5927 - dense_2_acc_20: 0.5903 - dense_2_acc_21: 0.5911 - dense_2_acc_22: 0.5966 - dense_2_acc_23: 0.5892 - dense_2_acc_24: 0.5898 - dense_2_acc_25: 0.5960 - dense_2_acc_26: 0.5904 - dense_2_a\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69421/69421 [==============================] - 73s 1ms/step - loss: 51.3403 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0641 - dense_2_acc_1: 0.2424 - dense_2_acc_2: 0.2951 - dense_2_acc_3: 0.3442 - dense_2_acc_4: 0.4121 - dense_2_acc_5: 0.4615 - dense_2_acc_6: 0.4973 - dense_2_acc_7: 0.5258 - dense_2_acc_8: 0.5421 - dense_2_acc_9: 0.5580 - dense_2_acc_10: 0.5721 - dense_2_acc_11: 0.5757 - dense_2_acc_12: 0.5800 - dense_2_acc_13: 0.5863 - dense_2_acc_14: 0.5857 - dense_2_acc_15: 0.5875 - dense_2_acc_16: 0.5924 - dense_2_acc_17: 0.5893 - dense_2_acc_18: 0.5908 - dense_2_acc_19: 0.5938 - dense_2_acc_20: 0.5911 - dense_2_acc_21: 0.5915 - dense_2_acc_22: 0.5963 - dense_2_acc_23: 0.5918 - dense_2_acc_24: 0.5917 - dense_2_acc_25: 0.5957 - dense_2_acc_26: 0.5920 - dense_2_acc_27: 0.5911 - dense_2_acc_28: 0.5955 - dense_2_acc_29: 1.4405e-05\n",
      "Epoch 12/20\n",
      "69421/69421 [==============================] - 76s 1ms/step - loss: 51.2725 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0645 - dense_2_acc_1: 0.2427 - dense_2_acc_2: 0.2942 - dense_2_acc_3: 0.3442 - dense_2_acc_4: 0.4126 - dense_2_acc_5: 0.4613 - dense_2_acc_6: 0.4977 - dense_2_acc_7: 0.5263 - dense_2_acc_8: 0.5421 - dense_2_acc_9: 0.5583 - dense_2_acc_10: 0.5715 - dense_2_acc_11: 0.5760 - dense_2_acc_12: 0.5804 - dense_2_acc_13: 0.5859 - dense_2_acc_14: 0.5863 - dense_2_acc_15: 0.5891 - dense_2_acc_16: 0.5924 - dense_2_acc_17: 0.5913 - dense_2_acc_18: 0.5914 - dense_2_acc_19: 0.5949 - dense_2_acc_20: 0.5926 - dense_2_acc_21: 0.5927 - dense_2_acc_22: 0.5971 - dense_2_acc_23: 0.5930 - dense_2_acc_24: 0.5916 - dense_2_acc_25: 0.5971 - dense_2_acc_26: 0.5928 - dense_2_acc_27: 0.5913 - dense_2_acc_28: 0.5960 - dense_2_acc_29: 2.8810e-05\n",
      "Epoch 13/20\n",
      "69421/69421 [==============================] - 75s 1ms/step - loss: 51.2118 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0625 - dense_2_acc_1: 0.2437 - dense_2_acc_2: 0.2942 - dense_2_acc_3: 0.3445 - dense_2_acc_4: 0.4127 - dense_2_acc_5: 0.4617 - dense_2_acc_6: 0.4967 - dense_2_acc_7: 0.5261 - dense_2_acc_8: 0.5426 - dense_2_acc_9: 0.5582 - dense_2_acc_10: 0.5733 - dense_2_acc_11: 0.5774 - dense_2_acc_12: 0.5802 - dense_2_acc_13: 0.5871 - dense_2_acc_14: 0.5873 - dense_2_acc_15: 0.5890 - dense_2_acc_16: 0.5933 - dense_2_acc_17: 0.5914 - dense_2_acc_18: 0.5918 - dense_2_acc_19: 0.5947 - dense_2_acc_20: 0.5925 - dense_2_acc_21: 0.5941 - dense_2_acc_22: 0.5976 - dense_2_acc_23: 0.5935 - dense_2_acc_24: 0.5928 - dense_2_acc_25: 0.5978 - dense_2_acc_26: 0.5927 - dense_2_acc_27: 0.5919 - dense_2_acc_28: 0.5973 - dense_2_acc_29: 2.8810e-05\n",
      "Epoch 14/20\n",
      "69421/69421 [==============================] - 76s 1ms/step - loss: 51.1580 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0643 - dense_2_acc_1: 0.2436 - dense_2_acc_2: 0.2947 - dense_2_acc_3: 0.3442 - dense_2_acc_4: 0.4131 - dense_2_acc_5: 0.4616 - dense_2_acc_6: 0.4978 - dense_2_acc_7: 0.5263 - dense_2_acc_8: 0.5435 - dense_2_acc_9: 0.5593 - dense_2_acc_10: 0.5728 - dense_2_acc_11: 0.5772 - dense_2_acc_12: 0.5809 - dense_2_acc_13: 0.5873 - dense_2_acc_14: 0.5871 - dense_2_acc_15: 0.5897 - dense_2_acc_16: 0.5942 - dense_2_acc_17: 0.5924 - dense_2_acc_18: 0.5931 - dense_2_acc_19: 0.5962 - dense_2_acc_20: 0.5935 - dense_2_acc_21: 0.5939 - dense_2_acc_22: 0.5978 - dense_2_acc_23: 0.5940 - dense_2_acc_24: 0.5937 - dense_2_acc_25: 0.5981 - dense_2_acc_26: 0.5937 - dense_2_acc_27: 0.5928 - dense_2_acc_28: 0.5978 - dense_2_acc_29: 2.8810e-05\n",
      "Epoch 15/20\n",
      "69421/69421 [==============================] - 74s 1ms/step - loss: 51.1096 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0639 - dense_2_acc_1: 0.2433 - dense_2_acc_2: 0.2949 - dense_2_acc_3: 0.3444 - dense_2_acc_4: 0.4129 - dense_2_acc_5: 0.4621 - dense_2_acc_6: 0.4977 - dense_2_acc_7: 0.5261 - dense_2_acc_8: 0.5436 - dense_2_acc_9: 0.5593 - dense_2_acc_10: 0.5734 - dense_2_acc_11: 0.5778 - dense_2_acc_12: 0.5817 - dense_2_acc_13: 0.5884 - dense_2_acc_14: 0.5878 - dense_2_acc_15: 0.5904 - dense_2_acc_16: 0.5948 - dense_2_acc_17: 0.5925 - dense_2_acc_18: 0.5934 - dense_2_acc_19: 0.5969 - dense_2_acc_20: 0.5941 - dense_2_acc_21: 0.5952 - dense_2_acc_22: 0.5995 - dense_2_acc_23: 0.5944 - dense_2_acc_24: 0.5944 - dense_2_acc_25: 0.5990 - dense_2_acc_26: 0.5939 - dense_2_acc_27: 0.5940 - dense_2_acc_28: 0.5986 - dense_2_acc_29: 2.8810e-05: 29s - loss: 51.0438 - dense_2_loss: 0.0000e+00 - de\n",
      "Epoch 16/20\n",
      "69421/69421 [==============================] - 76s 1ms/step - loss: 51.0664 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0644 - dense_2_acc_1: 0.2427 - dense_2_acc_2: 0.2944 - dense_2_acc_3: 0.3443 - dense_2_acc_4: 0.4135 - dense_2_acc_5: 0.4627 - dense_2_acc_6: 0.4980 - dense_2_acc_7: 0.5266 - dense_2_acc_8: 0.5437 - dense_2_acc_9: 0.5596 - dense_2_acc_10: 0.5739 - dense_2_acc_11: 0.5779 - dense_2_acc_12: 0.5819 - dense_2_acc_13: 0.5883 - dense_2_acc_14: 0.5879 - dense_2_acc_15: 0.5911 - dense_2_acc_16: 0.5956 - dense_2_acc_17: 0.5930 - dense_2_acc_18: 0.5943 - dense_2_acc_19: 0.5974 - dense_2_acc_20: 0.5942 - dense_2_acc_21: 0.5956 - dense_2_acc_22: 0.5991 - dense_2_acc_23: 0.5951 - dense_2_acc_24: 0.5951 - dense_2_acc_25: 0.5997 - dense_2_acc_26: 0.5950 - dense_2_acc_27: 0.5945 - dense_2_acc_28: 0.5986 - dense_2_acc_29: 2.8810e-05: 14s - loss: 51.0850 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0648 - dense_2_acc_1: 0.2425 - dense_2_acc_2: 0.2949 - dense_2_acc_3: 0.3441 - dense_2_acc_4: 0.4133 - dense_2_acc_5: 0.4629 - dense_2_acc_6: 0.4993 - dense_2_acc_7: 0.5247 - dense_2_acc_8: 0.5419 - dense_2_acc_9: 0.5609 - dense_2_acc_10: 0.5737 - dense_2_acc_11: 0.5766 - dense_2_acc_12: 0.5837 - dense_2_acc_13: 0.5883 - dense_2_acc_14: 0.5888 - dense_2_acc_15: 0.5897 - dense_2_acc_16: 0.5945 - dense_2_acc_17: 0.5926 - dense_2_acc_18: 0.5940 - dense_2_acc_19:\n",
      "Epoch 17/20\n",
      "69421/69421 [==============================] - 77s 1ms/step - loss: 51.0263 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0643 - dense_2_acc_1: 0.2430 - dense_2_acc_2: 0.2945 - dense_2_acc_3: 0.3443 - dense_2_acc_4: 0.4130 - dense_2_acc_5: 0.4630 - dense_2_acc_6: 0.4984 - dense_2_acc_7: 0.5271 - dense_2_acc_8: 0.5442 - dense_2_acc_9: 0.5600 - dense_2_acc_10: 0.5738 - dense_2_acc_11: 0.5777 - dense_2_acc_12: 0.5819 - dense_2_acc_13: 0.5884 - dense_2_acc_14: 0.5885 - dense_2_acc_15: 0.5909 - dense_2_acc_16: 0.5959 - dense_2_acc_17: 0.5948 - dense_2_acc_18: 0.5941 - dense_2_acc_19: 0.5976 - dense_2_acc_20: 0.5955 - dense_2_acc_21: 0.5958 - dense_2_acc_22: 0.6003 - dense_2_acc_23: 0.5962 - dense_2_acc_24: 0.5954 - dense_2_acc_25: 0.6003 - dense_2_acc_26: 0.5959 - dense_2_acc_27: 0.5949 - dense_2_acc_28: 0.5999 - dense_2_acc_29: 2.8810e-05: 42s - loss: 51.0200 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0630 - dense_2_acc_1: 0.2447 - dense_2_acc_2: 0.2964 - dense_2_acc_3:  - ETA: 19s - loss: 51.0425 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0637 - dense_2_acc_1: 0.2458 - dense_2_acc_2: 0.2943 - dense_2_acc_3: 0.3440 - dense_2_acc_4: 0.4130 - dense_2_acc_5: 0.4637 - dense_2_acc_6: 0.4983 - dense_2_acc_7: 0.5273 - dense_2_acc_8: 0.5429 - dense_2_acc_9: 0.5605 - dense_2_acc_10: 0.5730 - dense_2_acc_11: 0.5767 - dense_2_acc_12: 0.5820 - dense_2_acc_13: 0\n",
      "Epoch 18/20\n",
      "69421/69421 [==============================] - 77s 1ms/step - loss: 50.9899 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0644 - dense_2_acc_1: 0.2439 - dense_2_acc_2: 0.2942 - dense_2_acc_3: 0.3443 - dense_2_acc_4: 0.4132 - dense_2_acc_5: 0.4634 - dense_2_acc_6: 0.4977 - dense_2_acc_7: 0.5275 - dense_2_acc_8: 0.5448 - dense_2_acc_9: 0.5601 - dense_2_acc_10: 0.5740 - dense_2_acc_11: 0.5780 - dense_2_acc_12: 0.5822 - dense_2_acc_13: 0.5889 - dense_2_acc_14: 0.5888 - dense_2_acc_15: 0.5916 - dense_2_acc_16: 0.5964 - dense_2_acc_17: 0.5943 - dense_2_acc_18: 0.5948 - dense_2_acc_19: 0.5985 - dense_2_acc_20: 0.5955 - dense_2_acc_21: 0.5964 - dense_2_acc_22: 0.6005 - dense_2_acc_23: 0.5960 - dense_2_acc_24: 0.5959 - dense_2_acc_25: 0.6006 - dense_2_acc_26: 0.5957 - dense_2_acc_27: 0.5955 - dense_2_acc_28: 0.6001 - dense_2_acc_29: 2.8810e-05\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69421/69421 [==============================] - 76s 1ms/step - loss: 50.9560 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0644 - dense_2_acc_1: 0.2430 - dense_2_acc_2: 0.2951 - dense_2_acc_3: 0.3452 - dense_2_acc_4: 0.4133 - dense_2_acc_5: 0.4627 - dense_2_acc_6: 0.4978 - dense_2_acc_7: 0.5278 - dense_2_acc_8: 0.5451 - dense_2_acc_9: 0.5603 - dense_2_acc_10: 0.5744 - dense_2_acc_11: 0.5778 - dense_2_acc_12: 0.5827 - dense_2_acc_13: 0.5891 - dense_2_acc_14: 0.5887 - dense_2_acc_15: 0.5916 - dense_2_acc_16: 0.5969 - dense_2_acc_17: 0.5948 - dense_2_acc_18: 0.5956 - dense_2_acc_19: 0.5992 - dense_2_acc_20: 0.5967 - dense_2_acc_21: 0.5968 - dense_2_acc_22: 0.6010 - dense_2_acc_23: 0.5965 - dense_2_acc_24: 0.5962 - dense_2_acc_25: 0.6008 - dense_2_acc_26: 0.5964 - dense_2_acc_27: 0.5955 - dense_2_acc_28: 0.6006 - dense_2_acc_29: 2.8810e-05: 19s - loss: 50.9153 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0640 - dense_2_acc_1: 0.2437 - dense_2_acc_2: 0.2953 - dense_2_acc_3: 0.3461 - dense_2_acc_4: 0.4140 - dense_2_acc_5: 0.4623 - dense_2_acc_6: 0.4982 - dense_2_acc_7: 0.5290 - dense_2_acc_8: 0.5461 - dense_2_acc_9: 0.5604 - dense_2_acc_10: 0.5742 - dense_2_acc_11: 0.5771 - dense_2_acc_12: 0.5828 - dense_2_acc_\n",
      "Epoch 20/20\n",
      "69421/69421 [==============================] - 78s 1ms/step - loss: 50.9251 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0644 - dense_2_acc_1: 0.2436 - dense_2_acc_2: 0.2946 - dense_2_acc_3: 0.3449 - dense_2_acc_4: 0.4137 - dense_2_acc_5: 0.4632 - dense_2_acc_6: 0.4981 - dense_2_acc_7: 0.5278 - dense_2_acc_8: 0.5446 - dense_2_acc_9: 0.5606 - dense_2_acc_10: 0.5748 - dense_2_acc_11: 0.5785 - dense_2_acc_12: 0.5831 - dense_2_acc_13: 0.5892 - dense_2_acc_14: 0.5896 - dense_2_acc_15: 0.5918 - dense_2_acc_16: 0.5971 - dense_2_acc_17: 0.5951 - dense_2_acc_18: 0.5955 - dense_2_acc_19: 0.5992 - dense_2_acc_20: 0.5967 - dense_2_acc_21: 0.5967 - dense_2_acc_22: 0.6016 - dense_2_acc_23: 0.5971 - dense_2_acc_24: 0.5968 - dense_2_acc_25: 0.6012 - dense_2_acc_26: 0.5968 - dense_2_acc_27: 0.5961 - dense_2_acc_28: 0.6004 - dense_2_acc_29: 2.8810e-05\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr=0.1, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "m = 69421\n",
    "a0 = np.zeros((m, n_a))\n",
    "c0 = np.zeros((m, n_a))\n",
    "\n",
    "history=model.fit([X, a0, c0], list(Y2), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: music_inference_model\n",
    "\n",
    "def music_inference_model(LSTM_cell, densor, n_values = 88, n_a = 64, Ty = 100):\n",
    "    \"\"\"\n",
    "    Uses the trained \"LSTM_cell\" and \"densor\" from model() to generate a sequence of values.\n",
    "    \n",
    "    Arguments:\n",
    "    LSTM_cell -- the trained \"LSTM_cell\" from model(), Keras layer object\n",
    "    densor -- the trained \"densor\" from model(), Keras layer object\n",
    "    n_values -- integer, umber of unique values\n",
    "    n_a -- number of units in the LSTM_cell\n",
    "    Ty -- integer, number of time steps to generate\n",
    "    \n",
    "    Returns:\n",
    "    inference_model -- Keras model instance\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the input of your model with a shape \n",
    "    x0 = Input(shape=(1, n_values))\n",
    "    \n",
    "    # Define s0, initial hidden state for the decoder LSTM\n",
    "    a0 = Input(shape=(n_a,), name='a0')\n",
    "    c0 = Input(shape=(n_a,), name='c0')\n",
    "    a = a0\n",
    "    c = c0\n",
    "    x = x0\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    # Step 1: Create an empty list of \"outputs\" to later store your predicted values (≈1 line)\n",
    "    outputs =[]\n",
    "    \n",
    "    # Step 2: Loop over Ty and generate a value at every time step\n",
    "    for t in range(Ty):\n",
    "        #print(t)\n",
    "        # Step 2.A: Perform one step of LSTM_cell (≈1 line)\n",
    "        a, _, c = LSTM_cell(x, initial_state=[a, c])\n",
    "        \n",
    "        # Step 2.B: Apply Dense layer to the hidden state output of the LSTM_cell (≈1 line)\n",
    "        out = densor(a)\n",
    "\n",
    "        # Step 2.C: Append the prediction \"out\" to \"outputs\". out.shape = (None, 78) (≈1 line)\n",
    "        outputs.append(out)\n",
    "        print(out)\n",
    "        \n",
    "        # Step 2.D: Select the next value according to \"out\", and set \"x\" to be the one-hot representation of the\n",
    "        #           selected value, which will be passed as the input to LSTM_cell on the next step. We have provided \n",
    "        #           the line of code you need to do this. \n",
    "       # x = Lambda(one_hot)(out)\n",
    "       # x = Lambda(one_hot)(1)\n",
    "     #   out=K.cast(o,\"int32\")\n",
    "      #  x= Lambda(K.one_hot,\n",
    "        #       arguments={'num_classes':88},\n",
    "         #      output_shape=(1,1))(out)\n",
    "        x=reshapor(out)\n",
    "    \n",
    "        \n",
    "    # Step 3: Create model instance with the correct \"inputs\" and \"outputs\" (≈1 line)\n",
    "    inference_model = Model(inputs = [x0,a0,c0],outputs = outputs)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "   # return inference_model\n",
    "    return inference_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "gPrV5MZF8W1x",
    "outputId": "232e4d17-20bc-4c84-961b-3230b82dd818"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_2_30/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_31/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_32/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_33/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_34/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_35/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_36/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_37/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_38/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_39/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_40/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_41/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_42/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_43/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_44/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_45/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_46/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_47/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_48/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_49/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_50/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_51/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_52/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_53/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_54/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_55/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_56/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_57/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_58/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_59/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_60/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_61/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_62/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_63/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_64/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_65/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_66/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_67/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_68/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_69/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_70/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_71/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_72/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_73/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_74/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_75/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_76/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_77/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_78/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_79/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_80/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_81/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_82/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_83/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_84/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_85/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_86/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_87/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_88/Softmax:0\", shape=(?, 88), dtype=float32)\n",
      "Tensor(\"dense_2_89/Softmax:0\", shape=(?, 88), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "inference_model = music_inference_model(LSTM_cell, densor, n_values = 88, n_a = 64, Ty = 60)\n",
    "x_initializer = np.zeros((1, 1, 88))\n",
    "#x_initializer+=28\n",
    "a_initializer = np.zeros((1, n_a))\n",
    "c_initializer = np.zeros((1, n_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "8KaNNEBu8jHd"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: predict_and_sample\n",
    "\n",
    "def predict_and_sample(inference_model, x_initializer = x_initializer, a_initializer = a_initializer, \n",
    "                       c_initializer = c_initializer):\n",
    "    \"\"\"\n",
    "    Predicts the next value of values using the inference model.\n",
    "    \n",
    "    Arguments:\n",
    "    inference_model -- Keras model instance for inference time\n",
    "    x_initializer -- numpy array of shape (1, 1, 78), one-hot vector initializing the values generation\n",
    "    a_initializer -- numpy array of shape (1, n_a), initializing the hidden state of the LSTM_cell\n",
    "    c_initializer -- numpy array of shape (1, n_a), initializing the cell state of the LSTM_cel\n",
    "    \n",
    "    Returns:\n",
    "    results -- numpy-array of shape (Ty, 78), matrix of one-hot vectors representing the values generated\n",
    "    indices -- numpy-array of shape (Ty, 1), matrix of indices representing the values generated\n",
    "    \"\"\"\n",
    "    \n",
    "      ### START CODE HERE ###\n",
    "    # Step 1: Use your inference model to predict an output sequence given x_initializer, a_initializer and c_initializer.\n",
    "    pred = inference_model.predict([x_initializer, a_initializer, c_initializer])\n",
    "    # Step 2: Convert \"pred\" into an np.array() of indices with the maximum probabilities\n",
    "    indices = np.argmax(pred,axis = -1)\n",
    "    # Step 3: Convert indices to one-hot vectors, the shape of the results should be (1, )\n",
    "    results =to_categorical(indices)\n",
    "    \n",
    "    return results, indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate music and post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting new values for different set of chords.\n",
      "(1, 64)\n",
      "Generated 61 sounds using the predicted values for the set of chords (\"1\") and after pruning\n",
      "(1, 64)\n",
      "Generated 61 sounds using the predicted values for the set of chords (\"2\") and after pruning\n",
      "(1, 64)\n",
      "Generated 61 sounds using the predicted values for the set of chords (\"3\") and after pruning\n",
      "(1, 64)\n",
      "Generated 60 sounds using the predicted values for the set of chords (\"4\") and after pruning\n",
      "(1, 64)\n",
      "Generated 61 sounds using the predicted values for the set of chords (\"5\") and after pruning\n",
      "Your generated music is saved in output/my_music.mid\n"
     ]
    }
   ],
   "source": [
    "from music_utils import * \n",
    "from preprocess import * \n",
    "from keras.utils import to_categorical\n",
    "\n",
    "chords, abstract_grammars = get_musical_data('original_metheny.mid')\n",
    "corpus, tones, tones_indices, indices_tones = get_corpus_data(abstract_grammars)\n",
    "N_tones = len(set(corpus))\n",
    "n_a = 64\n",
    "x_initializer = np.zeros((1, 1, 88))\n",
    "a_initializer = np.zeros((1, n_a))\n",
    "c_initializer = np.zeros((1, n_a))\n",
    "\n",
    "def load_music_utils():\n",
    "    chords, abstract_grammars = get_musical_data('original_metheny.mid')\n",
    "    corpus, tones, tones_indices, indices_tones = get_corpus_data(abstract_grammars)\n",
    "    N_tones = len(set(corpus))\n",
    "    X, Y, N_tones = data_processing(corpus, tones_indices, 60, 30)   \n",
    "    return (X, Y, N_tones, indices_tones)\n",
    "\n",
    "\n",
    "def generate_music(inference_model, corpus = corpus, abstract_grammars = abstract_grammars, tones = tones, tones_indices = tones_indices, indices_tones = indices_tones, T_y = 10, max_tries = 1000, diversity = 0.5):\n",
    "    \"\"\"\n",
    "    Generates music using a model trained to learn musical patterns of a jazz soloist. Creates an audio stream\n",
    "    to save the music and play it.\n",
    "    \n",
    "    Arguments:\n",
    "    model -- Keras model Instance, output of djmodel()\n",
    "    corpus -- musical corpus, list of 193 tones as strings (ex: 'C,0.333,<P1,d-5>')\n",
    "    abstract_grammars -- list of grammars, on element can be: 'S,0.250,<m2,P-4> C,0.250,<P4,m-2> A,0.250,<P4,m-2>'\n",
    "    tones -- set of unique tones, ex: 'A,0.250,<M2,d-4>' is one element of the set.\n",
    "    tones_indices -- a python dictionary mapping unique tone (ex: A,0.250,< m2,P-4 >) into their corresponding indices (0-77)\n",
    "    indices_tones -- a python dictionary mapping indices (0-77) into their corresponding unique tone (ex: A,0.250,< m2,P-4 >)\n",
    "    Tx -- integer, number of time-steps used at training time\n",
    "    temperature -- scalar value, defines how conservative/creative the model is when generating music\n",
    "    \n",
    "    Returns:\n",
    "    predicted_tones -- python list containing predicted tones\n",
    "    \"\"\"\n",
    "    \n",
    "    # set up audio stream\n",
    "    out_stream = stream.Stream()\n",
    "    \n",
    "    # Initialize chord variables\n",
    "    curr_offset = 0.0                                     # variable used to write sounds to the Stream.\n",
    "    num_chords = int(len(chords) / 3)                     # number of different set of chords\n",
    "    \n",
    "    print(\"Predicting new values for different set of chords.\")\n",
    "    # Loop over all 18 set of chords. At each iteration generate a sequence of tones\n",
    "    # and use the current chords to convert it into actual sounds \n",
    "    for i in range(1, num_chords):\n",
    "        \n",
    "        # Retrieve current chord from stream\n",
    "        curr_chords = stream.Voice()\n",
    "        \n",
    "        # Loop over the chords of the current set of chords\n",
    "        for j in chords[i]:\n",
    "            # Add chord to the current chords with the adequate offset, no need to understand this\n",
    "            curr_chords.insert((j.offset % 4), j)\n",
    "        \n",
    "        # Generate a sequence of tones using the model\n",
    "        _, indices = predict_and_sample(inference_model)\n",
    "        indices = list(indices.squeeze())\n",
    "        pred = [indices_tones[p] for p in indices]\n",
    "        \n",
    "        predicted_tones = 'C,0.25 '\n",
    "        for k in range(len(pred) - 1):\n",
    "            predicted_tones += pred[k] + ' ' \n",
    "        \n",
    "        predicted_tones +=  pred[-1]\n",
    "                \n",
    "        #### POST PROCESSING OF THE PREDICTED TONES ####\n",
    "        # We will consider \"A\" and \"X\" as \"C\" tones. It is a common choice.\n",
    "        predicted_tones = predicted_tones.replace(' A',' C').replace(' X',' C')\n",
    "\n",
    "        # Pruning #1: smoothing measure\n",
    "        predicted_tones = prune_grammar(predicted_tones)\n",
    "        \n",
    "        # Use predicted tones and current chords to generate sounds\n",
    "        sounds = unparse_grammar(predicted_tones, curr_chords)\n",
    "\n",
    "        # Pruning #2: removing repeated and too close together sounds\n",
    "        sounds = prune_notes(sounds)\n",
    "\n",
    "        # Quality assurance: clean up sounds\n",
    "        sounds = clean_up_notes(sounds)\n",
    "\n",
    "        # Print number of tones/notes in sounds\n",
    "        print('Generated %s sounds using the predicted values for the set of chords (\"%s\") and after pruning' % (len([k for k in sounds if isinstance(k, note.Note)]), i))\n",
    "        \n",
    "        # Insert sounds into the output stream\n",
    "        for m in sounds:\n",
    "            out_stream.insert(curr_offset + m.offset, m)\n",
    "        for mc in curr_chords:\n",
    "            out_stream.insert(curr_offset + mc.offset, mc)\n",
    "\n",
    "        curr_offset += 4.0\n",
    "        \n",
    "    # Initialize tempo of the output stream with 130 bit per minute\n",
    "    out_stream.insert(0.0, tempo.MetronomeMark(number=130))\n",
    "\n",
    "    # Save audio stream to fine\n",
    "    mf = midi.translate.streamToMidiFile(out_stream)\n",
    "    mf.open(\"output/my_music.mid\", 'wb')\n",
    "    mf.write()\n",
    "    print(\"Your generated music is saved in output/my_music.mid\")\n",
    "    mf.close()\n",
    "    \n",
    "    # Play the final stream through output (see 'play' lambda function above)\n",
    "    # play = lambda x: midi.realtime.StreamPlayer(x).play()\n",
    "    # play(out_stream)\n",
    "    \n",
    "    return out_stream\n",
    "\n",
    "\n",
    "def predict_and_sample(inference_model, x_initializer = x_initializer, a_initializer = a_initializer, \n",
    "                       c_initializer = c_initializer):\n",
    "    \"\"\"\n",
    "    Predicts the next value of values using the inference model.\n",
    "    \n",
    "    Arguments:\n",
    "    inference_model -- Keras model instance for inference time\n",
    "    x_initializer -- numpy array of shape (1, 1, 78), one-hot vector initializing the values generation\n",
    "    a_initializer -- numpy array of shape (1, n_a), initializing the hidden state of the LSTM_cell\n",
    "    c_initializer -- numpy array of shape (1, n_a), initializing the cell state of the LSTM_cel\n",
    "    Ty -- length of the sequence you'd like to generate.\n",
    "    \n",
    "    Returns:\n",
    "    results -- numpy-array of shape (Ty, 78), matrix of one-hot vectors representing the values generated\n",
    "    indices -- numpy-array of shape (Ty, 1), matrix of indices representing the values generated\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    print(c_initializer.shape)\n",
    "    pred = inference_model.predict([x_initializer, a_initializer, c_initializer])\n",
    "    indices = np.argmax(pred, axis = -1)\n",
    "    results = to_categorical(indices, num_classes=88)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return results, indices\n",
    "out_stream = generate_music(inference_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eFXCHquBq6Gz"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Modelling using LSTM.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
