{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8x6ArWv2Kgv6",
    "outputId": "368f6ad7-a47c-4b00-96e7-825065640cd1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikhi\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, LSTM\n",
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "from keras.optimizers import RMSprop\n",
    "#from google.colab import drive\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "55DK6tUDKchp"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "with open(\"t.txt\",\"w\")as f:\n",
    "  f.write(\"hello\")\n",
    "data=pd.read_csv(\"piano_train_30.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "id": "XAU1Kv0CKchu",
    "outputId": "f52d2367-38e0-4ed5-93d9-ce71f802fa11"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>next_note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>79</td>\n",
       "      <td>62</td>\n",
       "      <td>86</td>\n",
       "      <td>62</td>\n",
       "      <td>86</td>\n",
       "      <td>62</td>\n",
       "      <td>86</td>\n",
       "      <td>62</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>62</td>\n",
       "      <td>86</td>\n",
       "      <td>63</td>\n",
       "      <td>87</td>\n",
       "      <td>65</td>\n",
       "      <td>89</td>\n",
       "      <td>62</td>\n",
       "      <td>86</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86</td>\n",
       "      <td>62</td>\n",
       "      <td>86</td>\n",
       "      <td>62</td>\n",
       "      <td>86</td>\n",
       "      <td>62</td>\n",
       "      <td>86</td>\n",
       "      <td>62</td>\n",
       "      <td>86</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>87</td>\n",
       "      <td>65</td>\n",
       "      <td>89</td>\n",
       "      <td>62</td>\n",
       "      <td>86</td>\n",
       "      <td>63</td>\n",
       "      <td>87</td>\n",
       "      <td>62</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>86</td>\n",
       "      <td>62</td>\n",
       "      <td>86</td>\n",
       "      <td>62</td>\n",
       "      <td>86</td>\n",
       "      <td>62</td>\n",
       "      <td>86</td>\n",
       "      <td>62</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>89</td>\n",
       "      <td>62</td>\n",
       "      <td>86</td>\n",
       "      <td>63</td>\n",
       "      <td>87</td>\n",
       "      <td>62</td>\n",
       "      <td>86</td>\n",
       "      <td>60</td>\n",
       "      <td>84</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>62</td>\n",
       "      <td>86</td>\n",
       "      <td>62</td>\n",
       "      <td>86</td>\n",
       "      <td>62</td>\n",
       "      <td>86</td>\n",
       "      <td>60</td>\n",
       "      <td>84</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>87</td>\n",
       "      <td>62</td>\n",
       "      <td>86</td>\n",
       "      <td>60</td>\n",
       "      <td>84</td>\n",
       "      <td>60</td>\n",
       "      <td>84</td>\n",
       "      <td>58</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>86</td>\n",
       "      <td>62</td>\n",
       "      <td>86</td>\n",
       "      <td>60</td>\n",
       "      <td>84</td>\n",
       "      <td>58</td>\n",
       "      <td>82</td>\n",
       "      <td>60</td>\n",
       "      <td>84</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>60</td>\n",
       "      <td>84</td>\n",
       "      <td>60</td>\n",
       "      <td>84</td>\n",
       "      <td>58</td>\n",
       "      <td>82</td>\n",
       "      <td>58</td>\n",
       "      <td>82</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4   5   6   7   8   9    ...      21  22  23  24  25  26  \\\n",
       "0  55  79  62  86  62  86  62  86  62  86    ...      84  62  86  63  87  65   \n",
       "1  86  62  86  62  86  62  86  62  86  62    ...      63  87  65  89  62  86   \n",
       "2  62  86  62  86  62  86  62  86  62  86    ...      89  62  86  63  87  62   \n",
       "3  86  62  86  62  86  62  86  60  84  58    ...      63  87  62  86  60  84   \n",
       "4  62  86  62  86  60  84  58  82  60  84    ...      86  60  84  60  84  58   \n",
       "\n",
       "   27  28  29  next_note  \n",
       "0  89  62  86         63  \n",
       "1  63  87  62         86  \n",
       "2  86  60  84         60  \n",
       "3  60  84  58         82  \n",
       "4  82  58  82         56  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "RBHSQ8C-Kchz"
   },
   "outputs": [],
   "source": [
    "sub_sequences= data.iloc[:,:30].values\n",
    "next_steps=data.iloc[:,30].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hkbfYbf-Kch3",
    "outputId": "75a9aa8b-3f5f-4cdd-e733-044f94e96515"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (76187, 30, 88)\n"
     ]
    }
   ],
   "source": [
    "len_notes=88\n",
    "maxlen=30\n",
    "\n",
    "X = np.zeros((len(sub_sequences), maxlen, len_notes), dtype=np.uint8 )\n",
    "Y = np.zeros((len(sub_sequences), len_notes), dtype=np.uint8)\n",
    "for i, seq in enumerate(sub_sequences):\n",
    "    #print(seq)\n",
    "    for t, note in enumerate(seq):\n",
    "        X[i, t, note-21] = 1\n",
    "        Y[i, note-21] = 1\n",
    "print(\"x shape:\",np.array(X).shape)\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "0E-MiJqZKch9"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, LSTM\n",
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "from keras.optimizers import RMSprop\n",
    "#from google.colab import drive\n",
    "import numpy as np\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "S9uxH2uaKciD"
   },
   "source": [
    "char_rnn = Sequential()\n",
    "char_rnn.add(LSTM(32, input_shape=(maxlen, 88)))\n",
    "char_rnn.add(Dense(88,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "7mNiGyyNKciI"
   },
   "outputs": [],
   "source": [
    "\n",
    "#char_rnn.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01),metrics=[\"acc\"])\n",
    "#char_rnn.fit(X,Y, epochs=50, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "IPkkU3WlKciQ",
    "outputId": "2cb0936c-58bb-444b-9883-58d015f51538"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (76187, 30, 88)\n",
      "y2 shape: (30, 76187, 88)\n"
     ]
    }
   ],
   "source": [
    "## LSTM\n",
    "len_notes=88\n",
    "\n",
    "\n",
    "maxlen=30\n",
    "\n",
    "X = np.zeros((len(sub_sequences), maxlen, len_notes), dtype=np.uint8 )\n",
    "Y2 = np.zeros((maxlen, len(sub_sequences),  len_notes), dtype=np.uint8)\n",
    "for i, seq in enumerate(sub_sequences):\n",
    "    #print(seq)\n",
    "    for t, note in enumerate(seq):\n",
    "        \n",
    "\n",
    "        if t>0:\n",
    "            X[i, t, note-21] = 1\n",
    "            Y2[t-1, i, note-21] = 1\n",
    "print(\"x shape:\",np.array(X).shape)\n",
    "print(\"y2 shape:\",np.array(Y2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "fh-3KeujKciW"
   },
   "outputs": [],
   "source": [
    "n_a = 64 \n",
    "n_values=88\n",
    "reshapor = Reshape((1, 88))                        # Used in Step 2.B of djmodel(), below\n",
    "LSTM_cell = LSTM(n_a,return_state=True)         # Used in Step 2.C\n",
    "densor = Dense(n_values, activation='softmax')     # Used in Step 2.D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "XUZG8MD5KciY"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# GRADED FUNCTION: djmodel\n",
    "\n",
    "def djmodel(Tx, n_a, n_values):\n",
    "    \"\"\"\n",
    "    Implement the model\n",
    "    \n",
    "    Arguments:\n",
    "    Tx -- length of the sequence in a corpus\n",
    "    n_a -- the number of activations used in our model\n",
    "    n_values -- number of unique values in the music data \n",
    "    \n",
    "    Returns:\n",
    "    model -- a keras model with the \n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input of your model with a shape \n",
    "    X = Input(shape=(Tx, n_values))\n",
    "    \n",
    "    # Define s0, initial hidden state for the decoder LSTM\n",
    "    a0 = Input(shape=(n_a,), name='a0')\n",
    "    c0 = Input(shape=(n_a,), name='c0')\n",
    "    a = a0\n",
    "    c = c0\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    # Step 1: Create empty list to append the outputs while you iterate (≈1 line)\n",
    "    outputs = []\n",
    "    \n",
    "    # Step 2: Loop\n",
    "    for t in range(Tx):\n",
    "        \n",
    "        # Step 2.A: select the \"t\"th time step vector from X. \n",
    "        x = Lambda(lambda x: X[:,t,:])(X) #Wraps arbitrary expression as a Layer object.\n",
    "        # Step 2.B: Use reshapor to reshape x to be (1, n_values) (≈1 line)\n",
    "        x =reshapor(x)    \n",
    "        # Step 2.C: Perform one step of the LSTM_cell\n",
    "        a, _, c = LSTM_cell(x, initial_state=[a, c])\n",
    "        #LSTM_cell(x, initial_state=[a, c])\n",
    "        # Step 2.D: Apply densor to the hidden state output of LSTM_Cell\n",
    "        out = densor(a)\n",
    "        # Step 2.E: add the output to \"outputs\"\n",
    "        outputs.append(out)\n",
    "        \n",
    "    # Step 3: Create model instance\n",
    "    model = Model(inputs = [X,a0,c0],outputs = outputs)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model\n",
    "model = djmodel(Tx = 30 , n_a = 64, n_values = 88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0T-aTTqcS3mC",
    "outputId": "ac1ddff4-dae5-4ad5-ad35-843846c81613"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76187, 30, 88)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "KwGu42rHKcic",
    "outputId": "38f529ef-4e13-4106-b06b-69846603a2e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "76187/76187 [==============================] - 57s 748us/step - loss: 66.0823 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0566 - dense_2_acc_1: 0.1776 - dense_2_acc_2: 0.2196 - dense_2_acc_3: 0.2701 - dense_2_acc_4: 0.3385 - dense_2_acc_5: 0.3916 - dense_2_acc_6: 0.4317 - dense_2_acc_7: 0.4400 - dense_2_acc_8: 0.4499 - dense_2_acc_9: 0.4557 - dense_2_acc_10: 0.4602 - dense_2_acc_11: 0.4559 - dense_2_acc_12: 0.4628 - dense_2_acc_13: 0.4624 - dense_2_acc_14: 0.4580 - dense_2_acc_15: 0.4622 - dense_2_acc_16: 0.4623 - dense_2_acc_17: 0.4572 - dense_2_acc_18: 0.4641 - dense_2_acc_19: 0.4624 - dense_2_acc_20: 0.4586 - dense_2_acc_21: 0.4633 - dense_2_acc_22: 0.4636 - dense_2_acc_23: 0.4579 - dense_2_acc_24: 0.4608 - dense_2_acc_25: 0.4613 - dense_2_acc_26: 0.4594 - dense_2_acc_27: 0.4600 - dense_2_acc_28: 0.4629 - dense_2_acc_29: 0.0000e+00\n",
      "Epoch 2/30\n",
      "76187/76187 [==============================] - 38s 497us/step - loss: 57.3010 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0581 - dense_2_acc_1: 0.1827 - dense_2_acc_2: 0.2319 - dense_2_acc_3: 0.2942 - dense_2_acc_4: 0.3788 - dense_2_acc_5: 0.4505 - dense_2_acc_6: 0.5006 - dense_2_acc_7: 0.5173 - dense_2_acc_8: 0.5281 - dense_2_acc_9: 0.5413 - dense_2_acc_10: 0.5463 - dense_2_acc_11: 0.5418 - dense_2_acc_12: 0.5524 - dense_2_acc_13: 0.5528 - dense_2_acc_14: 0.5474 - dense_2_acc_15: 0.5559 - dense_2_acc_16: 0.5550 - dense_2_acc_17: 0.5492 - dense_2_acc_18: 0.5569 - dense_2_acc_19: 0.5556 - dense_2_acc_20: 0.5501 - dense_2_acc_21: 0.5560 - dense_2_acc_22: 0.5556 - dense_2_acc_23: 0.5496 - dense_2_acc_24: 0.5545 - dense_2_acc_25: 0.5566 - dense_2_acc_26: 0.5480 - dense_2_acc_27: 0.5536 - dense_2_acc_28: 0.5554 - dense_2_acc_29: 0.0000e+00\n",
      "Epoch 3/30\n",
      "76187/76187 [==============================] - 39s 510us/step - loss: 55.7143 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1824 - dense_2_acc_2: 0.2344 - dense_2_acc_3: 0.2977 - dense_2_acc_4: 0.3857 - dense_2_acc_5: 0.4572 - dense_2_acc_6: 0.5099 - dense_2_acc_7: 0.5273 - dense_2_acc_8: 0.5399 - dense_2_acc_9: 0.5526 - dense_2_acc_10: 0.5580 - dense_2_acc_11: 0.5569 - dense_2_acc_12: 0.5665 - dense_2_acc_13: 0.5690 - dense_2_acc_14: 0.5645 - dense_2_acc_15: 0.5722 - dense_2_acc_16: 0.5725 - dense_2_acc_17: 0.5668 - dense_2_acc_18: 0.5740 - dense_2_acc_19: 0.5734 - dense_2_acc_20: 0.5668 - dense_2_acc_21: 0.5748 - dense_2_acc_22: 0.5725 - dense_2_acc_23: 0.5660 - dense_2_acc_24: 0.5740 - dense_2_acc_25: 0.5735 - dense_2_acc_26: 0.5648 - dense_2_acc_27: 0.5729 - dense_2_acc_28: 0.5727 - dense_2_acc_29: 1.3126e-0516s - loss: 55.8528 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0583 - dense_2_acc_1: 0.1848 - dense_2_acc_2: 0.2330 - dense_2_acc_3: 0.2972 - dense_2_acc_4: 0.3862 - dense_2_acc_5: 0.4571 - dense_2_acc_6: 0.5087 - dense_2_acc_7: 0.5283 - dense_2_acc_8: 0.5416 - dense_2_acc_9: 0.5516 - dense_2_acc_10: 0.5554 - dense_2_acc_11: 0.5541 - dense_2_acc_12: 0.5639 - dense_2_acc_13: 0.5653 - dense_2_acc_14: 0.5632 - dense_2_a\n",
      "Epoch 4/30\n",
      "76187/76187 [==============================] - 39s 514us/step - loss: 54.9549 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1820 - dense_2_acc_2: 0.2357 - dense_2_acc_3: 0.2988 - dense_2_acc_4: 0.3886 - dense_2_acc_5: 0.4606 - dense_2_acc_6: 0.5132 - dense_2_acc_7: 0.5325 - dense_2_acc_8: 0.5429 - dense_2_acc_9: 0.5581 - dense_2_acc_10: 0.5644 - dense_2_acc_11: 0.5627 - dense_2_acc_12: 0.5736 - dense_2_acc_13: 0.5768 - dense_2_acc_14: 0.5722 - dense_2_acc_15: 0.5798 - dense_2_acc_16: 0.5813 - dense_2_acc_17: 0.5739 - dense_2_acc_18: 0.5822 - dense_2_acc_19: 0.5818 - dense_2_acc_20: 0.5752 - dense_2_acc_21: 0.5817 - dense_2_acc_22: 0.5838 - dense_2_acc_23: 0.5746 - dense_2_acc_24: 0.5822 - dense_2_acc_25: 0.5822 - dense_2_acc_26: 0.5744 - dense_2_acc_27: 0.5806 - dense_2_acc_28: 0.5821 - dense_2_acc_29: 1.3126e-05\n",
      "Epoch 5/30\n",
      "76187/76187 [==============================] - 41s 537us/step - loss: 54.4936 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1822 - dense_2_acc_2: 0.2355 - dense_2_acc_3: 0.2999 - dense_2_acc_4: 0.3890 - dense_2_acc_5: 0.4627 - dense_2_acc_6: 0.5155 - dense_2_acc_7: 0.5344 - dense_2_acc_8: 0.5473 - dense_2_acc_9: 0.5615 - dense_2_acc_10: 0.5680 - dense_2_acc_11: 0.5664 - dense_2_acc_12: 0.5773 - dense_2_acc_13: 0.5803 - dense_2_acc_14: 0.5770 - dense_2_acc_15: 0.5845 - dense_2_acc_16: 0.5875 - dense_2_acc_17: 0.5812 - dense_2_acc_18: 0.5865 - dense_2_acc_19: 0.5884 - dense_2_acc_20: 0.5814 - dense_2_acc_21: 0.5879 - dense_2_acc_22: 0.5887 - dense_2_acc_23: 0.5800 - dense_2_acc_24: 0.5870 - dense_2_acc_25: 0.5884 - dense_2_acc_26: 0.5809 - dense_2_acc_27: 0.5861 - dense_2_acc_28: 0.5872 - dense_2_acc_29: 1.3126e-05\n",
      "Epoch 6/30\n",
      "76187/76187 [==============================] - 41s 538us/step - loss: 54.1768 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1819 - dense_2_acc_2: 0.2352 - dense_2_acc_3: 0.3011 - dense_2_acc_4: 0.3907 - dense_2_acc_5: 0.4640 - dense_2_acc_6: 0.5149 - dense_2_acc_7: 0.5363 - dense_2_acc_8: 0.5501 - dense_2_acc_9: 0.5639 - dense_2_acc_10: 0.5710 - dense_2_acc_11: 0.5696 - dense_2_acc_12: 0.5820 - dense_2_acc_13: 0.5838 - dense_2_acc_14: 0.5807 - dense_2_acc_15: 0.5877 - dense_2_acc_16: 0.5893 - dense_2_acc_17: 0.5837 - dense_2_acc_18: 0.5899 - dense_2_acc_19: 0.5921 - dense_2_acc_20: 0.5852 - dense_2_acc_21: 0.5910 - dense_2_acc_22: 0.5924 - dense_2_acc_23: 0.5850 - dense_2_acc_24: 0.5905 - dense_2_acc_25: 0.5921 - dense_2_acc_26: 0.5836 - dense_2_acc_27: 0.5888 - dense_2_acc_28: 0.5908 - dense_2_acc_29: 2.6251e-054s - loss: 54.1556 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0577 - dense_2_acc_1: 0.1825 - dense_2_acc_2: 0.2362 - dense_2_acc_3: 0.3017 - dense_2_acc_4: 0.3902 - dense_2_acc_5: 0.4641 - dense_2_acc_6: 0.5157 - dense_2_acc_7: 0.5371 - dense_2_acc_8: 0.5500 - dense_2_acc_9: 0.5632 - dense_2_acc_10: 0.5710 - dense_2_acc_11: 0.5694 - dense_2_acc_12: 0.5824 - dense_2_acc_13: 0.5852 - dense_2_acc_14: 0.5812 - dense_2_acc_15: 0.5878 - dense_2_acc_16: 0.5901 - dense_2_acc_17: 0.5839 - dense_2_acc_18: 0.5909 - dense_2_acc_19: 0.5923 - dense_2_acc_20: 0.5852 - dense_2_acc_21: 0.5911 - dense_2_acc_22: 0.5924 - dense_2_acc_23: 0.5855 - dense_2_acc_24: 0.5913 - dense_2_acc_25: 0.5931 - dense_2_acc_26: 0.5834 - dense_2_acc_27: 0.5886 - dense_2_acc_28: 0.5914 - dense_2_acc_2 - ETA: 3s - loss: 54.1703 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0579 - dense_2_acc_1: 0.1826 - dense_2_acc_2: 0.2362 - dense_2_acc_3: 0.3016 - dense_2_acc_4: 0.3904 - dense_2_acc_5: 0.4638 - dense_2_acc_6: 0.5152 - dense_2_acc_7: 0.5369 - dense_2_acc_8: 0.5496 - dense_2_acc_9: 0.5634 - dense_2_acc_10: 0.5708 - dense_2_acc_11: 0.5692 - dense_2_acc_12: 0.5823 - dense_2_acc_13: 0.5847 - dense_2_acc_14: 0.5809 - dense_2_acc_15: 0.5875 - dense_2_acc_16: 0.5898 - dense_2_acc_17: 0.5840 - dense_2_acc_18: 0.5906 - dense_2_acc_19: 0.5921 - dense_2_acc_20: 0.5852 - dense_2_acc_21: 0.5907 - dense_2_acc_22: 0.5924 - dense_2_acc_23: 0.5855 - dense_2_acc_24: 0.5910 - dense_2_acc_25: 0.5923 - dense_2_acc_26: 0.5835 - dense_2_acc_27: 0.5886 - dens\n",
      "Epoch 7/30\n",
      "76187/76187 [==============================] - 39s 506us/step - loss: 53.9441 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1809 - dense_2_acc_2: 0.2362 - dense_2_acc_3: 0.3004 - dense_2_acc_4: 0.3907 - dense_2_acc_5: 0.4648 - dense_2_acc_6: 0.5170 - dense_2_acc_7: 0.5369 - dense_2_acc_8: 0.5508 - dense_2_acc_9: 0.5650 - dense_2_acc_10: 0.5721 - dense_2_acc_11: 0.5712 - dense_2_acc_12: 0.5827 - dense_2_acc_13: 0.5857 - dense_2_acc_14: 0.5826 - dense_2_acc_15: 0.5903 - dense_2_acc_16: 0.5926 - dense_2_acc_17: 0.5863 - dense_2_acc_18: 0.5930 - dense_2_acc_19: 0.5955 - dense_2_acc_20: 0.5872 - dense_2_acc_21: 0.5931 - dense_2_acc_22: 0.5948 - dense_2_acc_23: 0.5871 - dense_2_acc_24: 0.5929 - dense_2_acc_25: 0.5948 - dense_2_acc_26: 0.5870 - dense_2_acc_27: 0.5917 - dense_2_acc_28: 0.5937 - dense_2_acc_29: 2.6251e-05\n",
      "Epoch 8/30\n",
      "76187/76187 [==============================] - 38s 502us/step - loss: 53.7655 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1819 - dense_2_acc_2: 0.2360 - dense_2_acc_3: 0.3004 - dense_2_acc_4: 0.3910 - dense_2_acc_5: 0.4661 - dense_2_acc_6: 0.5175 - dense_2_acc_7: 0.5388 - dense_2_acc_8: 0.5522 - dense_2_acc_9: 0.5668 - dense_2_acc_10: 0.5731 - dense_2_acc_11: 0.5725 - dense_2_acc_12: 0.5845 - dense_2_acc_13: 0.5871 - dense_2_acc_14: 0.5839 - dense_2_acc_15: 0.5919 - dense_2_acc_16: 0.5952 - dense_2_acc_17: 0.5894 - dense_2_acc_18: 0.5952 - dense_2_acc_19: 0.5976 - dense_2_acc_20: 0.5898 - dense_2_acc_21: 0.5954 - dense_2_acc_22: 0.5971 - dense_2_acc_23: 0.5893 - dense_2_acc_24: 0.5949 - dense_2_acc_25: 0.5963 - dense_2_acc_26: 0.5887 - dense_2_acc_27: 0.5934 - dense_2_acc_28: 0.5956 - dense_2_acc_29: 2.6251e-05\n",
      "Epoch 9/30\n",
      "76187/76187 [==============================] - 40s 523us/step - loss: 53.6249 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1816 - dense_2_acc_2: 0.2360 - dense_2_acc_3: 0.3012 - dense_2_acc_4: 0.3920 - dense_2_acc_5: 0.4654 - dense_2_acc_6: 0.5178 - dense_2_acc_7: 0.5394 - dense_2_acc_8: 0.5540 - dense_2_acc_9: 0.5679 - dense_2_acc_10: 0.5744 - dense_2_acc_11: 0.5743 - dense_2_acc_12: 0.5864 - dense_2_acc_13: 0.5894 - dense_2_acc_14: 0.5858 - dense_2_acc_15: 0.5935 - dense_2_acc_16: 0.5960 - dense_2_acc_17: 0.5901 - dense_2_acc_18: 0.5961 - dense_2_acc_19: 0.5990 - dense_2_acc_20: 0.5907 - dense_2_acc_21: 0.5966 - dense_2_acc_22: 0.5981 - dense_2_acc_23: 0.5912 - dense_2_acc_24: 0.5964 - dense_2_acc_25: 0.5979 - dense_2_acc_26: 0.5897 - dense_2_acc_27: 0.5959 - dense_2_acc_28: 0.5963 - dense_2_acc_29: 2.6251e-05\n",
      "Epoch 10/30\n",
      "76187/76187 [==============================] - 39s 513us/step - loss: 53.5084 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1817 - dense_2_acc_2: 0.2359 - dense_2_acc_3: 0.3014 - dense_2_acc_4: 0.3920 - dense_2_acc_5: 0.4660 - dense_2_acc_6: 0.5181 - dense_2_acc_7: 0.5399 - dense_2_acc_8: 0.5540 - dense_2_acc_9: 0.5687 - dense_2_acc_10: 0.5755 - dense_2_acc_11: 0.5747 - dense_2_acc_12: 0.5863 - dense_2_acc_13: 0.5911 - dense_2_acc_14: 0.5872 - dense_2_acc_15: 0.5946 - dense_2_acc_16: 0.5977 - dense_2_acc_17: 0.5928 - dense_2_acc_18: 0.5984 - dense_2_acc_19: 0.5999 - dense_2_acc_20: 0.5928 - dense_2_acc_21: 0.5983 - dense_2_acc_22: 0.6003 - dense_2_acc_23: 0.5928 - dense_2_acc_24: 0.5987 - dense_2_acc_25: 0.5999 - dense_2_acc_26: 0.5915 - dense_2_acc_27: 0.5983 - dense_2_acc_28: 0.5979 - dense_2_acc_29: 2.6251e-05\n",
      "Epoch 11/30\n",
      "76187/76187 [==============================] - 41s 534us/step - loss: 53.4078 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1820 - dense_2_acc_2: 0.2354 - dense_2_acc_3: 0.3023 - dense_2_acc_4: 0.3919 - dense_2_acc_5: 0.4665 - dense_2_acc_6: 0.5192 - dense_2_acc_7: 0.5414 - dense_2_acc_8: 0.5543 - dense_2_acc_9: 0.5692 - dense_2_acc_10: 0.5761 - dense_2_acc_11: 0.5748 - dense_2_acc_12: 0.5860 - dense_2_acc_13: 0.5915 - dense_2_acc_14: 0.5874 - dense_2_acc_15: 0.5954 - dense_2_acc_16: 0.5995 - dense_2_acc_17: 0.5933 - dense_2_acc_18: 0.5991 - dense_2_acc_19: 0.6013 - dense_2_acc_20: 0.5939 - dense_2_acc_21: 0.5999 - dense_2_acc_22: 0.6009 - dense_2_acc_23: 0.5939 - dense_2_acc_24: 0.5996 - dense_2_acc_25: 0.6002 - dense_2_acc_26: 0.5937 - dense_2_acc_27: 0.5984 - dense_2_acc_28: 0.5987 - dense_2_acc_29: 2.6251e-051s - loss: 53.4120 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0583 - dense_2_acc_1: 0.1819 - dense_2_acc_2: 0.2356 - dense_2_acc_3: 0.3026 - dense_2_acc_4: 0.3915 - dense_2_acc_5: 0.4662 - dense_2_acc_6: 0.5190 - dense_2_acc_7: 0.5413 - dense_2_acc_8: 0.5541 - dense_2_acc_9: 0.5696 - dense_2_acc_10: 0.5760 - dense_2_acc_11: 0.5746 - dense_2_acc_12: 0.5858 - dense_2_acc_13: 0.5913 - dense_2_acc_14: 0.5872 - dense_2_acc_15: 0.5957 - dense_2_acc_16: 0.5994 - dense_2_acc_17: 0.5935 - dense_2_acc_18: 0.5991 - dense_2_acc_19: 0.6010 - dense_2_acc_20: 0.5938 - dense_2_acc_21: 0.6005 - dense_2_acc_22: 0.6005 - dense_2_acc_23: 0.5941 - dense_2_acc_24: 0.6002 - dense_2_acc_25: 0.6003 - dense_2_acc_26: 0.5937 - dense_2_acc_27: 0.5983 - dense_2_acc_28: 0.5989 - dense_\n",
      "Epoch 12/30\n",
      "76187/76187 [==============================] - 42s 558us/step - loss: 53.3272 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1822 - dense_2_acc_2: 0.2354 - dense_2_acc_3: 0.3018 - dense_2_acc_4: 0.3917 - dense_2_acc_5: 0.4664 - dense_2_acc_6: 0.5194 - dense_2_acc_7: 0.5414 - dense_2_acc_8: 0.5555 - dense_2_acc_9: 0.5699 - dense_2_acc_10: 0.5768 - dense_2_acc_11: 0.5769 - dense_2_acc_12: 0.5877 - dense_2_acc_13: 0.5920 - dense_2_acc_14: 0.5890 - dense_2_acc_15: 0.5959 - dense_2_acc_16: 0.6000 - dense_2_acc_17: 0.5937 - dense_2_acc_18: 0.6004 - dense_2_acc_19: 0.6017 - dense_2_acc_20: 0.5950 - dense_2_acc_21: 0.6005 - dense_2_acc_22: 0.6023 - dense_2_acc_23: 0.5952 - dense_2_acc_24: 0.6005 - dense_2_acc_25: 0.6021 - dense_2_acc_26: 0.5939 - dense_2_acc_27: 0.5999 - dense_2_acc_28: 0.6002 - dense_2_acc_29: 2.6251e-0520s - loss: 53.2910 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0586 - dense_2_acc_1: 0.1794 - dense_2_acc_2: 0.2361 - dense_2_acc_3: 0.2999 - dense_2_acc_4: 0.3917 - dense_2_acc_5: 0.4638 - dense_2_acc_6: 0.5225 - dense_2_acc_7: 0.5432 - dense_2_acc_8: 0.5577 - dense_2_acc_9: 0.5722 - dense_2_acc_10: 0.5779 - dense_2_acc_11: 0.5775 - dense_2_acc_12: 0.\n",
      "Epoch 13/30\n",
      "76187/76187 [==============================] - 42s 555us/step - loss: 53.2556 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1821 - dense_2_acc_2: 0.2355 - dense_2_acc_3: 0.3024 - dense_2_acc_4: 0.3922 - dense_2_acc_5: 0.4674 - dense_2_acc_6: 0.5197 - dense_2_acc_7: 0.5421 - dense_2_acc_8: 0.5557 - dense_2_acc_9: 0.5700 - dense_2_acc_10: 0.5769 - dense_2_acc_11: 0.5775 - dense_2_acc_12: 0.5892 - dense_2_acc_13: 0.5926 - dense_2_acc_14: 0.5891 - dense_2_acc_15: 0.5970 - dense_2_acc_16: 0.6003 - dense_2_acc_17: 0.5948 - dense_2_acc_18: 0.6018 - dense_2_acc_19: 0.6023 - dense_2_acc_20: 0.5944 - dense_2_acc_21: 0.6019 - dense_2_acc_22: 0.6029 - dense_2_acc_23: 0.5963 - dense_2_acc_24: 0.6014 - dense_2_acc_25: 0.6024 - dense_2_acc_26: 0.5950 - dense_2_acc_27: 0.6009 - dense_2_acc_28: 0.6012 - dense_2_acc_29: 2.6251e-0514s - loss: 53.2316 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0577 - dense_2_acc_1: 0.1819 - dense_2_acc_2: 0.2360 - dense_2_acc_3: 0.3017 - dense_2_acc_4: 0.3913 - dense_2_acc_5: 0.4672 - dense_2_acc_6: 0.5209 - dense_2_acc_7: 0.5424 - dense_2_acc_8: 0.5538 - dense_2_acc_9: 0.5680 - dense_2_acc_10: 0.5765 - dense_2_acc_11: 0.5763 - dense_2_acc_12: 0.5890 - dense_2_acc_13: 0.5919 - dense_2_acc_14: 0.5894 - dense_2_acc_15: 0.5967 - dense_2_acc_16: 0.6006 - dense_2_acc_17: 0.5967 - dense_2_acc_18: 0.601\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76187/76187 [==============================] - 37s 487us/step - loss: 53.1911 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1818 - dense_2_acc_2: 0.2351 - dense_2_acc_3: 0.3017 - dense_2_acc_4: 0.3919 - dense_2_acc_5: 0.4669 - dense_2_acc_6: 0.5199 - dense_2_acc_7: 0.5428 - dense_2_acc_8: 0.5568 - dense_2_acc_9: 0.5706 - dense_2_acc_10: 0.5770 - dense_2_acc_11: 0.5779 - dense_2_acc_12: 0.5881 - dense_2_acc_13: 0.5934 - dense_2_acc_14: 0.5896 - dense_2_acc_15: 0.5981 - dense_2_acc_16: 0.6012 - dense_2_acc_17: 0.5961 - dense_2_acc_18: 0.6023 - dense_2_acc_19: 0.6032 - dense_2_acc_20: 0.5965 - dense_2_acc_21: 0.6015 - dense_2_acc_22: 0.6043 - dense_2_acc_23: 0.5968 - dense_2_acc_24: 0.6027 - dense_2_acc_25: 0.6039 - dense_2_acc_26: 0.5956 - dense_2_acc_27: 0.6023 - dense_2_acc_28: 0.6026 - dense_2_acc_29: 2.6251e-05\n",
      "Epoch 15/30\n",
      "76187/76187 [==============================] - 37s 492us/step - loss: 53.1360 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1826 - dense_2_acc_2: 0.2355 - dense_2_acc_3: 0.3020 - dense_2_acc_4: 0.3919 - dense_2_acc_5: 0.4667 - dense_2_acc_6: 0.5204 - dense_2_acc_7: 0.5432 - dense_2_acc_8: 0.5566 - dense_2_acc_9: 0.5716 - dense_2_acc_10: 0.5784 - dense_2_acc_11: 0.5782 - dense_2_acc_12: 0.5894 - dense_2_acc_13: 0.5941 - dense_2_acc_14: 0.5903 - dense_2_acc_15: 0.5981 - dense_2_acc_16: 0.6014 - dense_2_acc_17: 0.5966 - dense_2_acc_18: 0.6023 - dense_2_acc_19: 0.6036 - dense_2_acc_20: 0.5973 - dense_2_acc_21: 0.6033 - dense_2_acc_22: 0.6050 - dense_2_acc_23: 0.5977 - dense_2_acc_24: 0.6039 - dense_2_acc_25: 0.6049 - dense_2_acc_26: 0.5966 - dense_2_acc_27: 0.6027 - dense_2_acc_28: 0.6024 - dense_2_acc_29: 2.6251e-0539s - loss: 54.4655 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0625 - dense_2_acc_1: 0.1589 - dense_2_acc_2: 0.2500 - dense_2_acc_3: 0.2995 - dense_2_acc_4: 0.3594 - dense_2_acc_5: 0.4740 - dense_2_acc_6: 0.5208 - dense_2_acc_7: 0.5573 - dense_2_acc_8: 0.5599 - dense_2_acc_9: 0.5859 - dense_2_acc_10: 0.5521 - dense_2_acc_11: 0.5677 - dense_2_acc_12: 0.6120 - dense_2_acc_13: 0.6172 - dense_2_acc_14: 0.5859 - dense_2_acc_15: 0.6042 - dense_2_acc_16: 0.5703 - dense_2_acc_17: 0.6172 - dense_2_acc_18: 0.5990 - dense_2_acc_19: 0.5677 - dense_2_acc_20: 0.5807 - dense_2_acc_21: 0.6224 - dense_2_acc_22: 0.5964 - dense_2_acc_23: 0.6016 - dense_2_acc_2 - ETA: 32s - loss: 53.2773 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0598 - dense_2_acc_1: 0.1845 - dense_2_acc_2: 0.2408 - dense_2_acc_3: 0.3033 - dense_2_acc_4: 0.3855 - dense_2_acc_5: 0.4696 - dense_2_acc_6: 0.5204 - dense_2_acc_7: 0.5391 - dense_2_acc_8: 0.5536 - dense_2_acc_9: 0.5697 - dense_2_acc_10: 0.5717 - dense_2_acc_11: 0.5728 - dense - ETA: 18s - loss: 53.1168 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0570 - dense_2_acc_1: 0.1847 - dense_2_acc_2: 0.2345 - dense_2_acc_3: 0.3041 - dense_2_acc_4: 0.3922 - dense_2_acc_5: 0.4683 - dense_2_acc_6: 0.5230 - dense_2_acc_7: 0.5447 - dense_2_acc_8: 0.5550 - dense_2_acc_9: 0.5722 - dense_2_acc_10: 0.5775 - dense_2_acc_11: 0.5823 - dense_2_\n",
      "Epoch 16/30\n",
      "76187/76187 [==============================] - 37s 488us/step - loss: 53.0849 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1824 - dense_2_acc_2: 0.2358 - dense_2_acc_3: 0.3019 - dense_2_acc_4: 0.3924 - dense_2_acc_5: 0.4671 - dense_2_acc_6: 0.5202 - dense_2_acc_7: 0.5429 - dense_2_acc_8: 0.5571 - dense_2_acc_9: 0.5717 - dense_2_acc_10: 0.5786 - dense_2_acc_11: 0.5786 - dense_2_acc_12: 0.5891 - dense_2_acc_13: 0.5949 - dense_2_acc_14: 0.5911 - dense_2_acc_15: 0.5989 - dense_2_acc_16: 0.6019 - dense_2_acc_17: 0.5970 - dense_2_acc_18: 0.6042 - dense_2_acc_19: 0.6046 - dense_2_acc_20: 0.5983 - dense_2_acc_21: 0.6039 - dense_2_acc_22: 0.6052 - dense_2_acc_23: 0.5989 - dense_2_acc_24: 0.6044 - dense_2_acc_25: 0.6058 - dense_2_acc_26: 0.5974 - dense_2_acc_27: 0.6034 - dense_2_acc_28: 0.6037 - dense_2_acc_29: 2.6251e-05\n",
      "Epoch 17/30\n",
      "76187/76187 [==============================] - 38s 499us/step - loss: 53.0390 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1828 - dense_2_acc_2: 0.2356 - dense_2_acc_3: 0.3022 - dense_2_acc_4: 0.3919 - dense_2_acc_5: 0.4675 - dense_2_acc_6: 0.5206 - dense_2_acc_7: 0.5430 - dense_2_acc_8: 0.5573 - dense_2_acc_9: 0.5712 - dense_2_acc_10: 0.5781 - dense_2_acc_11: 0.5789 - dense_2_acc_12: 0.5898 - dense_2_acc_13: 0.5949 - dense_2_acc_14: 0.5912 - dense_2_acc_15: 0.5993 - dense_2_acc_16: 0.6023 - dense_2_acc_17: 0.5977 - dense_2_acc_18: 0.6044 - dense_2_acc_19: 0.6055 - dense_2_acc_20: 0.5988 - dense_2_acc_21: 0.6041 - dense_2_acc_22: 0.6058 - dense_2_acc_23: 0.5988 - dense_2_acc_24: 0.6052 - dense_2_acc_25: 0.6057 - dense_2_acc_26: 0.5983 - dense_2_acc_27: 0.6045 - dense_2_acc_28: 0.6043 - dense_2_acc_29: 2.6251e-05\n",
      "Epoch 18/30\n",
      "76187/76187 [==============================] - 38s 496us/step - loss: 52.9979 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1827 - dense_2_acc_2: 0.2351 - dense_2_acc_3: 0.3020 - dense_2_acc_4: 0.3926 - dense_2_acc_5: 0.4677 - dense_2_acc_6: 0.5202 - dense_2_acc_7: 0.5435 - dense_2_acc_8: 0.5575 - dense_2_acc_9: 0.5718 - dense_2_acc_10: 0.5790 - dense_2_acc_11: 0.5790 - dense_2_acc_12: 0.5901 - dense_2_acc_13: 0.5955 - dense_2_acc_14: 0.5914 - dense_2_acc_15: 0.5995 - dense_2_acc_16: 0.6025 - dense_2_acc_17: 0.5975 - dense_2_acc_18: 0.6042 - dense_2_acc_19: 0.6060 - dense_2_acc_20: 0.5988 - dense_2_acc_21: 0.6051 - dense_2_acc_22: 0.6062 - dense_2_acc_23: 0.5996 - dense_2_acc_24: 0.6056 - dense_2_acc_25: 0.6070 - dense_2_acc_26: 0.5981 - dense_2_acc_27: 0.6045 - dense_2_acc_28: 0.6048 - dense_2_acc_29: 2.6251e-05\n",
      "Epoch 19/30\n",
      "76187/76187 [==============================] - 38s 497us/step - loss: 52.9576 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1825 - dense_2_acc_2: 0.2357 - dense_2_acc_3: 0.3019 - dense_2_acc_4: 0.3924 - dense_2_acc_5: 0.4673 - dense_2_acc_6: 0.5210 - dense_2_acc_7: 0.5438 - dense_2_acc_8: 0.5575 - dense_2_acc_9: 0.5724 - dense_2_acc_10: 0.5794 - dense_2_acc_11: 0.5792 - dense_2_acc_12: 0.5901 - dense_2_acc_13: 0.5958 - dense_2_acc_14: 0.5916 - dense_2_acc_15: 0.5999 - dense_2_acc_16: 0.6030 - dense_2_acc_17: 0.5985 - dense_2_acc_18: 0.6046 - dense_2_acc_19: 0.6062 - dense_2_acc_20: 0.5994 - dense_2_acc_21: 0.6060 - dense_2_acc_22: 0.6071 - dense_2_acc_23: 0.5998 - dense_2_acc_24: 0.6057 - dense_2_acc_25: 0.6075 - dense_2_acc_26: 0.5993 - dense_2_acc_27: 0.6042 - dense_2_acc_28: 0.6061 - dense_2_acc_29: 2.6251e-05\n",
      "Epoch 20/30\n",
      "76187/76187 [==============================] - 38s 499us/step - loss: 52.9232 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1827 - dense_2_acc_2: 0.2357 - dense_2_acc_3: 0.3019 - dense_2_acc_4: 0.3923 - dense_2_acc_5: 0.4681 - dense_2_acc_6: 0.5207 - dense_2_acc_7: 0.5440 - dense_2_acc_8: 0.5573 - dense_2_acc_9: 0.5726 - dense_2_acc_10: 0.5792 - dense_2_acc_11: 0.5796 - dense_2_acc_12: 0.5907 - dense_2_acc_13: 0.5964 - dense_2_acc_14: 0.5918 - dense_2_acc_15: 0.6005 - dense_2_acc_16: 0.6038 - dense_2_acc_17: 0.5987 - dense_2_acc_18: 0.6057 - dense_2_acc_19: 0.6065 - dense_2_acc_20: 0.6004 - dense_2_acc_21: 0.6064 - dense_2_acc_22: 0.6083 - dense_2_acc_23: 0.6000 - dense_2_acc_24: 0.6069 - dense_2_acc_25: 0.6079 - dense_2_acc_26: 0.5992 - dense_2_acc_27: 0.6051 - dense_2_acc_28: 0.6056 - dense_2_acc_29: 2.6251e-05\n",
      "Epoch 21/30\n",
      "76187/76187 [==============================] - 37s 484us/step - loss: 52.8898 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1825 - dense_2_acc_2: 0.2347 - dense_2_acc_3: 0.3025 - dense_2_acc_4: 0.3924 - dense_2_acc_5: 0.4674 - dense_2_acc_6: 0.5210 - dense_2_acc_7: 0.5437 - dense_2_acc_8: 0.5581 - dense_2_acc_9: 0.5723 - dense_2_acc_10: 0.5799 - dense_2_acc_11: 0.5799 - dense_2_acc_12: 0.5907 - dense_2_acc_13: 0.5965 - dense_2_acc_14: 0.5919 - dense_2_acc_15: 0.6010 - dense_2_acc_16: 0.6034 - dense_2_acc_17: 0.5994 - dense_2_acc_18: 0.6061 - dense_2_acc_19: 0.6072 - dense_2_acc_20: 0.6002 - dense_2_acc_21: 0.6058 - dense_2_acc_22: 0.6084 - dense_2_acc_23: 0.6002 - dense_2_acc_24: 0.6068 - dense_2_acc_25: 0.6081 - dense_2_acc_26: 0.5997 - dense_2_acc_27: 0.6053 - dense_2_acc_28: 0.6057 - dense_2_acc_29: 2.6251e-05\n",
      "Epoch 22/30\n",
      "76187/76187 [==============================] - 37s 482us/step - loss: 52.8606 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1829 - dense_2_acc_2: 0.2351 - dense_2_acc_3: 0.3024 - dense_2_acc_4: 0.3924 - dense_2_acc_5: 0.4676 - dense_2_acc_6: 0.5210 - dense_2_acc_7: 0.5439 - dense_2_acc_8: 0.5584 - dense_2_acc_9: 0.5728 - dense_2_acc_10: 0.5791 - dense_2_acc_11: 0.5796 - dense_2_acc_12: 0.5907 - dense_2_acc_13: 0.5968 - dense_2_acc_14: 0.5929 - dense_2_acc_15: 0.6009 - dense_2_acc_16: 0.6038 - dense_2_acc_17: 0.5995 - dense_2_acc_18: 0.6063 - dense_2_acc_19: 0.6072 - dense_2_acc_20: 0.6004 - dense_2_acc_21: 0.6077 - dense_2_acc_22: 0.6087 - dense_2_acc_23: 0.6014 - dense_2_acc_24: 0.6073 - dense_2_acc_25: 0.6086 - dense_2_acc_26: 0.5997 - dense_2_acc_27: 0.6056 - dense_2_acc_28: 0.6065 - dense_2_acc_29: 2.6251e-05\n",
      "Epoch 23/30\n",
      "76187/76187 [==============================] - 37s 486us/step - loss: 52.8298 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1830 - dense_2_acc_2: 0.2347 - dense_2_acc_3: 0.3023 - dense_2_acc_4: 0.3926 - dense_2_acc_5: 0.4683 - dense_2_acc_6: 0.5213 - dense_2_acc_7: 0.5438 - dense_2_acc_8: 0.5579 - dense_2_acc_9: 0.5731 - dense_2_acc_10: 0.5798 - dense_2_acc_11: 0.5805 - dense_2_acc_12: 0.5908 - dense_2_acc_13: 0.5965 - dense_2_acc_14: 0.5923 - dense_2_acc_15: 0.6016 - dense_2_acc_16: 0.6039 - dense_2_acc_17: 0.5998 - dense_2_acc_18: 0.6063 - dense_2_acc_19: 0.6075 - dense_2_acc_20: 0.6010 - dense_2_acc_21: 0.6080 - dense_2_acc_22: 0.6086 - dense_2_acc_23: 0.6019 - dense_2_acc_24: 0.6077 - dense_2_acc_25: 0.6088 - dense_2_acc_26: 0.6007 - dense_2_acc_27: 0.6061 - dense_2_acc_28: 0.6071 - dense_2_acc_29: 2.6251e-058s - loss: 52.7812 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0578 - dense_2_acc_1: 0.1839 - dense_2_acc_2: 0.2342 - dense_2_acc_3: 0.3024 - dense_2_acc_4: 0.3916 - dense_2_acc_5: 0.4676 - dense_2_acc_6: 0.5226 - dense_2_acc_7: 0.5431 - dense_2_acc_8: 0.5595 - dense_2_acc_9: 0.5739 - dense_2_acc_10: 0.5790 - dense_2_acc_11: 0.5816 - dense_2_acc_12: 0.5925 - dense_2_acc_13: 0.5972 - dense_2_acc_14: 0.5930 - dense_2_acc_15: 0.6008 - dense_2_acc_16: 0.6058 - dense_2_acc_17: 0.5999 - dense_2_acc_18: 0.6069 - dense_2_acc_19: 0.6072 - dense_2_acc_20: 0.6013 - dense_2_acc_21: 0.6090 - dense_2_acc_22: 0.6094 - dense_2_acc_23: 0.6011 - dense_2_acc_24: \n",
      "Epoch 24/30\n",
      "76187/76187 [==============================] - 40s 522us/step - loss: 52.8036 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1830 - dense_2_acc_2: 0.2357 - dense_2_acc_3: 0.3027 - dense_2_acc_4: 0.3925 - dense_2_acc_5: 0.4683 - dense_2_acc_6: 0.5214 - dense_2_acc_7: 0.5440 - dense_2_acc_8: 0.5584 - dense_2_acc_9: 0.5727 - dense_2_acc_10: 0.5801 - dense_2_acc_11: 0.5802 - dense_2_acc_12: 0.5908 - dense_2_acc_13: 0.5966 - dense_2_acc_14: 0.5934 - dense_2_acc_15: 0.6021 - dense_2_acc_16: 0.6048 - dense_2_acc_17: 0.6002 - dense_2_acc_18: 0.6075 - dense_2_acc_19: 0.6083 - dense_2_acc_20: 0.6020 - dense_2_acc_21: 0.6080 - dense_2_acc_22: 0.6091 - dense_2_acc_23: 0.6021 - dense_2_acc_24: 0.6084 - dense_2_acc_25: 0.6097 - dense_2_acc_26: 0.6007 - dense_2_acc_27: 0.6072 - dense_2_acc_28: 0.6073 - dense_2_acc_29: 2.6251e-05\n",
      "Epoch 25/30\n",
      "76187/76187 [==============================] - 38s 502us/step - loss: 52.7792 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1830 - dense_2_acc_2: 0.2347 - dense_2_acc_3: 0.3026 - dense_2_acc_4: 0.3927 - dense_2_acc_5: 0.4684 - dense_2_acc_6: 0.5213 - dense_2_acc_7: 0.5440 - dense_2_acc_8: 0.5587 - dense_2_acc_9: 0.5730 - dense_2_acc_10: 0.5798 - dense_2_acc_11: 0.5805 - dense_2_acc_12: 0.5915 - dense_2_acc_13: 0.5974 - dense_2_acc_14: 0.5932 - dense_2_acc_15: 0.6022 - dense_2_acc_16: 0.6042 - dense_2_acc_17: 0.6007 - dense_2_acc_18: 0.6074 - dense_2_acc_19: 0.6089 - dense_2_acc_20: 0.6024 - dense_2_acc_21: 0.6081 - dense_2_acc_22: 0.6096 - dense_2_acc_23: 0.6017 - dense_2_acc_24: 0.6080 - dense_2_acc_25: 0.6096 - dense_2_acc_26: 0.6004 - dense_2_acc_27: 0.6073 - dense_2_acc_28: 0.6072 - dense_2_acc_29: 2.6251e-0539s - loss: 54.4752 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0755 - dense_2_acc_1: 0.1458 - dense_2_acc_2: 0.2448 - dense_2_acc_3: 0.3177 - dense_2_acc_4: 0.3516 - dense_2_acc_5: 0.4557 - dense_2_acc_6: 0.5312 - dense_2_acc_7: 0.5573 - dense_2_acc_8: 0.5677 - dense_2_acc_9: 0.5573 - dense_2_acc_10: 0.5677 - dense_2_acc_11: 0.5859 - dense_2_acc_12: 0.5391 - dense_2_acc_13: 0.5964 - dense_2_acc_14: 0.6094 - dense_2_acc_15: 0.6198 - dense_2 - ETA: 26s - loss: 52.6388 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0609 - dense_2_acc_1: 0.1822 - dense_\n",
      "Epoch 26/30\n",
      "76187/76187 [==============================] - 38s 494us/step - loss: 52.7559 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1830 - dense_2_acc_2: 0.2351 - dense_2_acc_3: 0.3026 - dense_2_acc_4: 0.3927 - dense_2_acc_5: 0.4683 - dense_2_acc_6: 0.5216 - dense_2_acc_7: 0.5439 - dense_2_acc_8: 0.5592 - dense_2_acc_9: 0.5733 - dense_2_acc_10: 0.5804 - dense_2_acc_11: 0.5809 - dense_2_acc_12: 0.5915 - dense_2_acc_13: 0.5969 - dense_2_acc_14: 0.5928 - dense_2_acc_15: 0.6021 - dense_2_acc_16: 0.6048 - dense_2_acc_17: 0.6005 - dense_2_acc_18: 0.6078 - dense_2_acc_19: 0.6093 - dense_2_acc_20: 0.6019 - dense_2_acc_21: 0.6087 - dense_2_acc_22: 0.6102 - dense_2_acc_23: 0.6016 - dense_2_acc_24: 0.6087 - dense_2_acc_25: 0.6106 - dense_2_acc_26: 0.6014 - dense_2_acc_27: 0.6079 - dense_2_acc_28: 0.6078 - dense_2_acc_29: 2.6251e-052s - loss: 52.7628 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0580 - dense_2_acc_1: 0.1832 - dense_2_acc_2: 0.2353 - dense_2_acc_3: 0.3025 - dense_2_acc_4: 0.3928 - dense_2_acc_5: 0.4686 - dense_2_acc_6: 0.5213 - dense_2_acc_7: 0.5438 - dense_2_acc_8: 0.5597 - dense_2_acc_9: 0.5727 - dense_2_acc_10: 0.5806 - dense_2_acc_11: 0.5801 - dense_2_acc_12: 0.5916 - dense_2_acc_13: 0.5971 - dense_2_acc_14: 0.5931 - dense_2_acc_15: 0.6022 - dense_2_acc_16: 0.6045 - dense_2_acc_17: 0.6008 - dense_2_acc_18: 0.6076 - dense_2_acc_19: 0.6095 - dense_2_acc_20: 0.6021 - dense_2_acc_21: 0.6086 - dense_2_acc_22: 0.6098 - dense_2_acc_23: 0.6018 - dense_2_acc_24: 0.6084 - dense_2_acc_25: 0.6105 - dense_2_acc_26: 0.6015 - dense_2_acc_27: 0.6078 - dense_2_acc_28: \n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76187/76187 [==============================] - 38s 492us/step - loss: 52.7334 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1829 - dense_2_acc_2: 0.2346 - dense_2_acc_3: 0.3029 - dense_2_acc_4: 0.3923 - dense_2_acc_5: 0.4689 - dense_2_acc_6: 0.5209 - dense_2_acc_7: 0.5443 - dense_2_acc_8: 0.5588 - dense_2_acc_9: 0.5737 - dense_2_acc_10: 0.5808 - dense_2_acc_11: 0.5805 - dense_2_acc_12: 0.5915 - dense_2_acc_13: 0.5976 - dense_2_acc_14: 0.5939 - dense_2_acc_15: 0.6025 - dense_2_acc_16: 0.6061 - dense_2_acc_17: 0.6010 - dense_2_acc_18: 0.6085 - dense_2_acc_19: 0.6093 - dense_2_acc_20: 0.6026 - dense_2_acc_21: 0.6089 - dense_2_acc_22: 0.6101 - dense_2_acc_23: 0.6024 - dense_2_acc_24: 0.6091 - dense_2_acc_25: 0.6107 - dense_2_acc_26: 0.6018 - dense_2_acc_27: 0.6070 - dense_2_acc_28: 0.6085 - dense_2_acc_29: 2.6251e-0529s - loss: 52.6391 -\n",
      "Epoch 28/30\n",
      "76187/76187 [==============================] - 37s 483us/step - loss: 52.7128 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1830 - dense_2_acc_2: 0.2344 - dense_2_acc_3: 0.3028 - dense_2_acc_4: 0.3923 - dense_2_acc_5: 0.4684 - dense_2_acc_6: 0.5218 - dense_2_acc_7: 0.5444 - dense_2_acc_8: 0.5585 - dense_2_acc_9: 0.5737 - dense_2_acc_10: 0.5808 - dense_2_acc_11: 0.5810 - dense_2_acc_12: 0.5916 - dense_2_acc_13: 0.5976 - dense_2_acc_14: 0.5939 - dense_2_acc_15: 0.6022 - dense_2_acc_16: 0.6054 - dense_2_acc_17: 0.6010 - dense_2_acc_18: 0.6081 - dense_2_acc_19: 0.6089 - dense_2_acc_20: 0.6032 - dense_2_acc_21: 0.6091 - dense_2_acc_22: 0.6105 - dense_2_acc_23: 0.6019 - dense_2_acc_24: 0.6084 - dense_2_acc_25: 0.6105 - dense_2_acc_26: 0.6021 - dense_2_acc_27: 0.6078 - dense_2_acc_28: 0.6084 - dense_2_acc_29: 2.6251e-05\n",
      "Epoch 29/30\n",
      "76187/76187 [==============================] - 37s 485us/step - loss: 52.6922 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1830 - dense_2_acc_2: 0.2348 - dense_2_acc_3: 0.3026 - dense_2_acc_4: 0.3926 - dense_2_acc_5: 0.4688 - dense_2_acc_6: 0.5213 - dense_2_acc_7: 0.5446 - dense_2_acc_8: 0.5583 - dense_2_acc_9: 0.5740 - dense_2_acc_10: 0.5809 - dense_2_acc_11: 0.5810 - dense_2_acc_12: 0.5925 - dense_2_acc_13: 0.5973 - dense_2_acc_14: 0.5947 - dense_2_acc_15: 0.6023 - dense_2_acc_16: 0.6058 - dense_2_acc_17: 0.6017 - dense_2_acc_18: 0.6087 - dense_2_acc_19: 0.6101 - dense_2_acc_20: 0.6036 - dense_2_acc_21: 0.6096 - dense_2_acc_22: 0.6109 - dense_2_acc_23: 0.6031 - dense_2_acc_24: 0.6091 - dense_2_acc_25: 0.6111 - dense_2_acc_26: 0.6024 - dense_2_acc_27: 0.6083 - dense_2_acc_28: 0.6086 - dense_2_acc_29: 2.6251e-05\n",
      "Epoch 30/30\n",
      "76187/76187 [==============================] - 37s 488us/step - loss: 52.6746 - dense_2_loss: 0.0000e+00 - dense_2_acc: 0.0582 - dense_2_acc_1: 0.1831 - dense_2_acc_2: 0.2343 - dense_2_acc_3: 0.3028 - dense_2_acc_4: 0.3926 - dense_2_acc_5: 0.4683 - dense_2_acc_6: 0.5212 - dense_2_acc_7: 0.5449 - dense_2_acc_8: 0.5588 - dense_2_acc_9: 0.5740 - dense_2_acc_10: 0.5819 - dense_2_acc_11: 0.5813 - dense_2_acc_12: 0.5921 - dense_2_acc_13: 0.5981 - dense_2_acc_14: 0.5949 - dense_2_acc_15: 0.6021 - dense_2_acc_16: 0.6065 - dense_2_acc_17: 0.6011 - dense_2_acc_18: 0.6086 - dense_2_acc_19: 0.6096 - dense_2_acc_20: 0.6037 - dense_2_acc_21: 0.6094 - dense_2_acc_22: 0.6119 - dense_2_acc_23: 0.6037 - dense_2_acc_24: 0.6093 - dense_2_acc_25: 0.6114 - dense_2_acc_26: 0.6026 - dense_2_acc_27: 0.6091 - dense_2_acc_28: 0.6096 - dense_2_acc_29: 2.6251e-05\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr=0.1, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "m = 76187\n",
    "a0 = np.zeros((m, n_a))\n",
    "c0 = np.zeros((m, n_a))\n",
    "\n",
    "history=model.fit([X, a0, c0], list(Y2), batch_size=128,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEfCAYAAACqKwpQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4VeW59/HvnWEnJIGQBAizgLMERA0oIqK1KraOrba1\natVaqVat7Xs62MlTtcd6bHtOqW21tNapWge01mOr1bbOAxgUFQQFMUIYZAhTEjLf7x9rJYYMkECy\nV3b273NdufZe872yYd95hvU85u6IiIi0lBJ1ACIi0vsoOYiISBtKDiIi0oaSg4iItKHkICIibSg5\niIhIG0oO0ieY2UVm5mZ2XNSxxJuZPWtmpZ3c97jw93TRrtaJKDlIr9bii6vlT4WZLTCzq80sNeoY\nRfqitKgDEOmkPwN/BwwYDlwE/BIYD8wC7gHuB2ojii9KJxH8XvbU80A/oK57wpG+QMlBEsXr7v6n\npgUzuxVYAnzFzH7k7h8BDZFFFyF336uE6O6NQHU3hSN9hKqVJCG5+zbgFYK/mMe11+bQYt0nzOxb\nZva+mdWY2XtmdmHrc5rZ583sMTNbGe630cweNbOJ7cVgZmea2UthNVdF+P6Mzt5Di/hOMLNrzexD\nM9thZvPM7Khwnxlm9qKZVZrZWjP7UTvnabfNwczOMLM3zKzazFaZ2fVAejv7qc1B2lDJQRKSmRmw\nX7i4EThwF7vfSFBt8jugBrgcuNPMlrv7Sy32uxIoB+YA64B9CaqsXjKzw919WYvrfw34DbAU+Ang\nBFVdj5rZV919Thdu5yYgFZgNxID/AP4RJrDbw3juBT4HXG9mH7QsRbXHzM4CHgZKgeuBeuBi4NQu\nxCVJTMlBEkWWmQ0iKCkMA64CDgVedfdlZjZtF8dmAJObql/MbC6wgiAZtEwOM929suWBZnY3sBD4\nJvC1cF0ecDPwPnBkWIppqup6A/iFmT3o7ls6eW+pwFEt4nsH+CswF5jq7q+F628HPgSuADpMDmEj\n/WyCRDfF3TeG638HvNXJmCTJqVpJEsV1wAZgPfAm8GXgMeDMThz725b18u6+GngP2L/lTk2JwQID\nwmS0AXgXOLLFricC2cCvmhJDePw24BYgB/hkF+7t1lbtBi+Er682JYbw/LXA/NZxt+MIYBRwR1Ni\nCI/fCtzWhbgkiankIIliDvAQQfVNJfCeu5d38tgV7azbBOzTcoWZHQbcABxH8OXf0gct3o8NXxe3\nc95F4eu48Jy5BFVaLW1w95aN5zvF5+6bg1qzna7ZZDNQ0M76lsaFr0vb2fbObo4VAZQcJHEsc/d/\n7uGxHfViau7+aWajCbp0biNIEO8SJCEn6DKb095xnTAbaN34PZagLWB38e1p76um+NqbrGVvurxK\nElFyEAmcRZAATnf3Z1puMLMCgobsJu+Hr+OBf7U6zyHha1Np4Gbatg+s2+tod60pvoPb2dbeOpE2\n1OYgEmj6K32nv6zN7FJgaKt9nyYoVVxlZv1b7NufoKG8ItwHd3/H3f/Z6qennylYAJQBF4ftJk3x\nDQAu6+FrSx+hkoNI4AmgCrjHzH5NULc/DfgUwV/izf9X3H2LmX2HoCvrPDO7M9x0EUH32q+Gjb+R\ncPcGM/sm8CAw38x+T9CV9csEbS2jo4pNEodKDiKAu78PnELQCPx9gmcP8oEZBH+Ft97/t8BngC3A\nf4Y/W4CzuviMQ49w97nA2QRtKD8Gvk7QNfa7EYYlCcTc22uzEhGRZKaSg4iItKHkICIibSg5iIhI\nG0oOIiLSRsJ2ZR00aJCPGTMm6jBERBLKggULNrr74N3tl7DJYcyYMZSUlEQdhohIQjGzDzuzn6qV\nRESkDSUHERFpQ8lBRETaSNg2BxFJbHV1dZSVlVFd3dPjECanzMxMRo4cSXp6m2nDO0XJQUQiUVZW\nRv/+/RkzZgzh5EbSTdydTZs2UVZWxtixY3d/QDtUrSQikaiurqagoECJoQeYGQUFBXtVKot7cjCz\ngWY218yWmtkSM5sarr/KzN41s8VmdnO84xKR+FNi6Dl7+7uNolppNvCku59tZjEgy8yOB84AJrp7\njZkNiSAuEREJxbXkEM5EdSxwO4C717r7FuBy4CZ3rwnXr++pGO6bt5Jz57zaU6cXkQSSmprKpEmT\nKCoq4pxzzqGqqgqAo48+OuLIAo899hg33XRTu9tycoJpzdesWcPZZ5/d7deOd7XSOGADcIeZvWFm\nfzCzbOAAYLqZzTOz58xscnsHm9ksMysxs5INGzbsUQCbKmp4ZcUmausb9/gmRKRv6NevHwsXLmTR\nokXEYjFuu+02AF5++eWIIwucfvrpXHPNNbvcZ/jw4cydO7fbrx3v5JAGHA7c6u6HEczDe024Pg84\nCvg28KC1U2Hm7nPcvdjdiwcP3u3QIO3Ky44BsLmqdo+OF5G+afr06Sxfvhz4+K/yZ599luOOO46z\nzz6bgw46iPPOO4+mCdKuv/56Jk+eTFFREbNmzWpev3DhQo466igmTpzIWWedxebNm9tcq7S0lIMO\nOoivfOUrFBUVcd555/HPf/6TadOmsf/++zN//nwA7rzzTq688koAPvjgA6ZOncrkyZP50Y9+tNO5\nioqKuv33Ee82hzKgzN3nhctzCZJDGfCIB7/d+WbWCAwiKGV0q4IwOWyqqKVwQGZ3n15E9tDnf/dK\nm3WnThzGBVPHsKO2gYvumN9m+9lHjOSc4lGUV9Zy+Z8W7LTtga9O7fS16+vreeKJJ5g5c2abbW+8\n8QaLFy9m+PDhTJs2jZdeeoljjjmGK6+8kmuvvRaACy64gMcff5zTTjuNL33pS9xyyy3MmDGDa6+9\nluuuu45f/vKXbc67fPlyHnroIebMmcPkyZO57777ePHFF3nssce48cYbefTRR3fa/+qrr+byyy/n\nS1/6Er/5zW86fW97Kq4lB3dfB6wyswPDVScA7wCPAp8AMLMDgBiwsSdiyA+TQ3mlSg4iyW7Hjh1M\nmjSJ4uJiRo8ezSWXXNJmnylTpjBy5EhSUlKYNGkSpaWlADzzzDMceeSRTJgwgX//+98sXryYrVu3\nsmXLFmbMmAHAhRdeyPPPP9/utceOHcuECRNISUlh/PjxnHDCCZgZEyZMaL5GSy+99BLnnnsuECSj\nnhZFb6WrgHvDnkorgIsJqpf+aGaLgFrgQu+hya0LB2Ry6KiBpKWqC51Ib7Krv/T7xVJ3uT0/O9al\nkkLzecM2h13JyMhofp+amkp9fT3V1dV87Wtfo6SkhFGjRvHjH/94l88UrFq1itNOOw2Ayy67jJkz\nZ+503pSUlObllJQU6uvr2z1PPLv+xj05uPtCoLidTefH4/pjBmXz1yumxeNSItJHNSWCQYMGUVFR\nwdy5czn77LPJzc0lLy+PF154genTp3PPPfcwY8YMRo0atVMSaq9ksDvTpk3j/vvv5/zzz+fee+/t\nrlvpkIbPEBHpooEDB3LppZcyYcIExowZw+TJH3ewvOuuu7jsssuoqqpi3Lhx3HHHHd1yzdmzZ/PF\nL36R2bNn89nPfrZbzrkr1kO1Nz2uuLjY93Syny/+/lUOGz2Qb598UDdHJSKdtWTJEg4++OCow+jT\n2vsdm9kCd2+v9mYnSTm20vrtNazYUBl1GCIivVZSJof8rBib1FtJRKRDyZkcsmNsVnIQiVyiVmsn\ngr393SZncsiJ6TkHkYhlZmayadMmJYge0DSfQ2bmnj/om5S9lQ4dmcuWqlrcXUMGi0Rk5MiRlJWV\nsafjpMmuNc0Et6eSsreSiEiyUm8lERHZY0mZHBZ8WM4RNzxNSWl51KGIiPRKSZkcMtNT2VRZy8YK\nNUqLiLQnKZNDQXYwwJV6LImItC8pk0NedjoA5ZU1EUciItI7JWVyyEhLJScjTU9Ji4h0ICmTAwQz\nSI0fnht1GCIivVJSPgQH8OPTx0cdgohIr5W0JQeA+obGqEMQEemVkjY5/PDRtzn25meiDkNEpFdK\n2uSQHUtjY2WtBv0SEWlH0iaHvOwYtfWNVNY2RB2KiEivk7TJIT87BkC5npIWEWkj7snBzAaa2Vwz\nW2pmS8xsaott3zIzN7NBPR1HQVNyqFJyEBFpLYqurLOBJ939bDOLAVkAZjYKOBFYGY8g9h2cw1eO\nGUteVno8LiciklDiWnIwswHAscDtAO5e6+5bws3/C3wHiEsL8ZhB2fzw1EPYpyA7HpcTEUko8a5W\nGgdsAO4wszfM7A9mlm1mpwOr3f3NXR1sZrPMrMTMSvZ29ih3p6q2noqa+r06j4hIXxTv5JAGHA7c\n6u6HAZXAj4EfANfu7mB3n+Puxe5ePHjw4L0OZtJ1T3PLv5ft9XlERPqaeCeHMqDM3eeFy3MJksVY\n4E0zKwVGAq+b2dCeDMTMyMtOV28lEZF2xDU5uPs6YJWZHRiuOgF43d2HuPsYdx9DkEAOD/ftUfnZ\nGWxWbyURkTai6K10FXBv2FNpBXBxBDEAQXdWDdstItJW3JODuy8EinexfUy8YsnPjrFqc1W8Lici\nkjCSdshugNMPHc7kMXlRhyEi0uskdXL45CGFUYcgItIrJe3YSgDVdQ2s2FBBTb0G3xMRaSmpk8Mz\nS9fziV88x/vrK6MORUSkV0nq5NA8Mqt6LImI7CSpk0NBjkZmFRFpT1Inh7yspjkdaiKORESkd0nq\n5DAwK4aZqpVERFpL6q6sqSnGjWdNYPzwAVGHIiLSqyR1cgA4d8roqEMQEel1krpaCWDlpioWrd4a\ndRgiIr1K0ieHG/++hG8+sDDqMEREepWkTw552TE1SIuItJL0yaEgO8bmqloaG+MydbWISEJI+uSQ\nnx2j0WHrjrqoQxER6TWSPjk0PSWtSX9ERD6W9Mlhyth8bjv/CIYMyIg6FBGRXiPpn3MYltuPYbn9\nog5DRKRXSfqSQ11DI8+9t4EPNmrYbhGRJkmfHBrdufCP8/nbW2uiDkVEpNeIe3Iws4FmNtfMlprZ\nEjObamY/C5ffMrO/mNnAeMWTkZZKTkaaGqRFRFqIouQwG3jS3Q8CDgWWAE8DRe4+EXgP+F48A8rP\njrFZyUFEpFlck4OZDQCOBW4HcPdad9/i7k+5e32426vAyHjGlZ8dU8lBRKSFeJccxgEbgDvM7A0z\n+4OZZbfa58vAE+0dbGazzKzEzEo2bNjQbUHlawgNEZGdxDs5pAGHA7e6+2FAJXBN00Yz+wFQD9zb\n3sHuPsfdi929ePDgwd0W1LdPPpCbz57YbecTEUl08X7OoQwoc/d54fJcwuRgZhcCpwInuHtcBzo6\neJgm+xERaSmuJQd3XwesMrMDw1UnAO+Y2Uzgu8Dp7l4Vz5gASjdW8uBrq6iua4j3pUVEeqUonpC+\nCrjXzGLACuBi4DUgA3jazABedffL4hXQ/NJyvvPwW0zdt4BR+VnxuqyISK8V9+Tg7guB4lar94t3\nHC0VZH88+J6Sg4iInpAGggl/AMorayKORESkd1ByoEXJoULdWUVEQMkBCJ5zANhcpeQgIgIashuA\nnIw0/vb1YxiZp/YGERFQcgDAzBg/PDfqMEREeg1VK4WeeHst//emhu0WEQGVHJrdO28llbX1nHbo\n8KhDERGJnEoOIQ3bLSLyMSWHkIbtFhH5mJJDqCA7xvbqemrrG6MORUQkckoOofwcPesgItJEDdKh\nMyaNYOb4oeRlxaIORUQkckoOoZyMNHIy9OsQEQFVKzXbWlXHL556lzdXbYk6FBGRyCk5hOobG7nl\n38t5Y+XmqEMREYmckkNoYFYMMyhXd1YRESWHJqkpRl6WnnUQEQElh53kZaWr5CAigpLDTgqyM9i6\noy7qMEREIrfXfTfN7BDgYOAVd0/oYU3vvmQKGWnKlyIiXfomNLNfm9ltLZY/A7wJPAS8Y2aTuzm+\nuMpMT8XMog5DRCRyXf0z+RTg5RbL1wGPA4cC84H/3N0JzGygmc01s6VmtsTMpppZvpk9bWbLwte8\nLsbVLZ5/bwPfmfsmjY0exeVFRHqNriaHoUApgJmNBMYDP3X3t4FfAZ0pOcwGnnT3gwiSyhLgGuBf\n7r4/8K9wOe6Wr6/gwZIytTuISNLranLYAeSE72cA24CScLkC6L+rg81sAHAscDuAu9e6+xbgDOCu\ncLe7gDO7GFe3KAgH31N3VhFJdl1NDq8DV5hZEXAF8LS7N41xPRZYu5vjxwEbgDvM7A0z+4OZZQOF\n7r4WIHwd0t7BZjbLzErMrGTDhg1dDH338rM1MquICHQ9OfwAOIqgEfpA4IYW284kaHfYlTTgcOBW\ndz8MqKQLVUjuPsfdi929ePDgwV0KvDOaRmTdVKHkICLJrUtdWd39NTMbDRwELHP3bS02zwGW7eYU\nZUCZu88Ll+cSJIePzGyYu681s2HA+q7E1V0KcmJkxVKprmuI4vIiIr1Gl59zcPdKYEHLdWZW4O5/\n68Sx68xslZkd6O7vAicA74Q/FwI3ha9/7Wpc3WFYbj/euX5mFJcWEelVupQczOxSYKC7/yxcngA8\nAQwzszeAU9193W5OcxVwr5nFgBXAxQTVWw+a2SXASuCcrt2GiIh0p662OVxF0GOpyf8AW4BvALnA\n9bs7gbsvDNsNJrr7me6+2d03ufsJ7r5/+Frexbi6zU8ef4dbn30/qsuLiPQKXa1WGg0sBTCzXILu\nrGe6+9/NbBPw026OL+5e+3AzAzLTuPy4faMORUQkMl0tOaQCTV1XjwEceDZcXkUHXVATSUF2TCOz\nikjS62pyWAZ8Onz/BeBld68Kl4cDkVUHdZd8JQcRkS5XK/0cuMfMLgTy2Lnh+Hjgre4KLCr52cGE\nP+6uQfhEJGl19TmH+8xsJXAk8Jq7P99i80fAY90ZXBRGDOzHiIH9qKlvJDM9NepwREQiYe6JOQJp\ncXGxl5SU7H5HERFpZmYL3L14d/t1+SE4M8sCvkzQUykf2ETQKH1ni/YHERFJYF2d7GcoweB7vwKK\ngSyCYbp/DSwws8JujzDOSjdW8oU5rzD/g4RvWxcR2WNd7a10M0FD9HR3H+vuU919LEG31oHAf3d3\ngPGWYsarK8pZWa5CkIgkrz2ZCe577v5Sy5Xu/jLwQz7u5pqw8rLTASivrIk4EhGR6HQ1OeQAazrY\nVsbHEwElrJyMNGKpKZrwR0SSWleTw7vABR1sO59waI1EZmbkZaezWclBRJLYnjwEd3fY8Hwfwcxv\nQwmelv4kHSeOhHLEPnkM7p8RdRgiIpHp6kNwfwq7sl4P/KHFpo+Ar7r7fd0ZXFR+e94RUYcgIhKp\nrlYr4e5zCMZRGg9MD19HAKVmlvDDZ4iIyB4kBwB3b3T3Je7+UvjaSDCfw/juDS8at7/4Aafe8kLU\nYYiIRGaPkkNfV1lTz6LV26ip11zSIpKclBzakZ8dA2BLVV3EkYiIREPJoR0FYXLYVKHurCKSnHbb\nW8nMxnXyXEP3MpZeo6nkoEl/RCRZdaYr63KC6UB3xzqzn5mVAtuBBqDe3YvNbBJwG5AJ1ANfc/f5\nnbhmjxiW24/p+w+iX0zzOYhIcupMcri4B657vLtvbLF8M3Cduz9hZp8Kl4/rget2yuiCLO655Mio\nLi8iErndJgd3vysOcTgwIHyfS8fjN4mISBxE0SDtwFNmtsDMZoXrvgH8zMxWEQzR8b32DjSzWWZW\nYmYlGzZs6NEgT73lBW54/J0evYaISG8VRXKY5u6HEwz/fYWZHQtcDnzT3UcB3wRub+9Ad5/j7sXu\nXjx48OAeDXJHbQNrt+7o0WuIiPRWcU8O7r4mfF0P/AWYAlwIPBLu8lC4LlIF2RnqyioiSSuuycHM\nss2sf9N74CRgEUEbw4xwt08Ay+IZV3vystPVlVVEklZXh+zeW4XAX8ys6dr3ufuTZlYBzDazNKAa\nmLWLc8RFfnYGJaWbow5DRCQScU0O7r4COLSd9S8CvWqc7CPH5tO5xztERPqeeJccEsaZh43gzMNG\nRB2GiEgkNLbSLrg7jY0qPYhI8lFy6MCrKzZxwA+foORDtTuISPJRcuhATkYadQ1OeWVN1KGIiMSd\nkkMHBuVkAFC2WQ/CiUjyUXLoQOGADMYPH8D9r61Su4OIJB0lhw6YGV+ZPpbl6yt47r2eHcdJRKS3\nUVfWXTh14nDKK+s4fHRe1KGIiMSVksMupKemcMkxY6MOQ0Qk7lSt1AlPvL2WX/0r8uGeRETiRsmh\nE+aXlvOrfy1j3dbqqEMREYkLJYdO+PK0sTS6c+fLpVGHIiISF0oOnTAqP4tTioZx37wPqaypjzoc\nEZEep+TQSZdMH8u26noeLFkVdSgiIj1OyaGTDh+dxzlHjGTogMyoQxER6XHqytoFPzunzVQUIiJ9\nkkoOXVRRU8+jb6yOOgwRkR6l5NBFj7xexjceWMgCDeUtIn2YkkMXffbwkQzITOMPL6yIOhQRkR6j\n5NBF2RlpnHfUPvxj8TpWbqqKOhwRkR6h5LAHLjp6DKkpxh9f+iDqUEREekTck4OZlZrZ22a20MxK\nWqy/yszeNbPFZnZzvOPqisIBmZx26HA+3FSJu+Z6EJG+J6qurMe7+8amBTM7HjgDmOjuNWY2JKK4\nOu2nn5lARlpq1GGIiPSI3lKtdDlwk7vXALj7+ojj2a2mxLB+ezW19Y0RRyMi0r2iSA4OPGVmC8xs\nVrjuAGC6mc0zs+fMbHJ7B5rZLDMrMbOSDRuin53t3XXbOeamZ/i/N9dEHYqISLeKIjlMc/fDgVOA\nK8zsWILqrTzgKODbwINmZq0PdPc57l7s7sWDBw+Oa9DtOaAwh30Ksvj9CyvU9iAifUrck4O7rwlf\n1wN/AaYAZcAjHpgPNAKD4h1bVzXNM7103XZefn9T1OGIiHSbuCYHM8s2s/5N74GTgEXAo8AnwvUH\nADFgY0fn6U3OmDSCQTkxfvvschobVXoQkb4h3iWHQuBFM3sTmA/8zd2fBP4IjDOzRcD9wIWeIPU0\nmempXHH8fsz/oJwl67ZFHY6ISLeIa1dWd18BtBna1N1rgfPjGUt3uujoMUzffzD7DcmJOhQRkW7R\nW7qyJjQza04Mf124mjv05LSIJDjN59CN3J1/LF7H399eR3ZGGp8rHhV1SCIie0TJoRuZGf/7+Uls\nry7hmoffon9GGqdMGBZ1WCIiXaZqpW6WkZbK7y44gsNG5/H1+9/g+feif1hPRKSrlBx6QFYsjT9e\nNJn9hvTn9ZWaFEhEEo+qlXpIbr90Hrn8aPrFgjGYGhudlJQ2D32LiPRKKjn0oKbEsHjNVk6Z/QIr\nNlREHJGISOcoOcRBv/RUNlbUcP4f5rF6y46owxER2S0lhzgYNziHuy+Zwvaaes7/wzzWKEGISC+n\n5BAn44fncsdFk/loWzUn/e/zLF6zNeqQREQ6pOQQR8Vj8nny6mP57OEjOLCwP4AmChKRXknJIc5G\nF2Rx3RlFpKWmsKWqlk/84llue+596huUJESk91ByiFB9o3PwsAHc9MRSzvrty7yzRqO6ikjvoOQQ\noUE5Gcy54Ah+88XDWbt1B6f/+kV+/o93adC8ECISMT0EFzEz49MTh3H0vgX85G9LWLpuO3pWTkSi\npuTQS+Rlx/jF5w6lrqERM6N0YyW3v/gBl04fx+iCrKjDE5Eko2qlXiY9NfhIXly+kftfW8mMnz/D\nZfcs4LXSchJkcjwR6QNUcuilzj9qH048pJC7XynlT6+u5MnF65g6roD7Lj0SM9U7iUjPUnLoxQoH\nZPLtkw/iiuP34+HXV1NRXY+Z4e48VFLGyUVDye2XHnWYItIHWaJWVRQXF3tJSUnUYURi0eqtnHrL\ni2THUvnc5FFcfPRYtUuISKeY2QJ3L97dfnFvczCzUjN728wWmllJq23fMjM3s0HxjiuRFI3I5fGr\njuGk8UO555UPOe7nz3DunFc1ZpOIdJuoqpWOd/eNLVeY2SjgRGBlNCEllqIRufzv5yfx3ZkHcd/8\nlTz/3gYKcmIAPPjaKipq6plZNJThA/tFHKmIJKK4VyuZWSlQ3E5ymAvcAPy1ve2tJXO10u5cds8C\nnly8DoBJowbyqQlDOaVoGKPyVfUkkux6bbUS4MBTZrbAzGYBmNnpwGp3f3NXB5rZLDMrMbOSDRs0\nN3NHbrvgCP79HzP49skHUt/YyI1/X8p//W1J8/bXV27WgH8isktRlByGu/saMxsCPA1cBfwMOMnd\nt3ZUsmhNJYfOW1VeRU19A/sN6c+q8iqm3/wMmekpHLFPHlPHFXDUuAImjhxILE2PvYj0db225ODu\na8LX9cBfgBnAWODNMDGMBF43s6Hxjq2vGpWfxX5DgiHCC3Ji/O6CI/jC5NFsqqjl50+9x9m3vcIT\ni9YCsH5bNSWl5SpZiCS5uDZIm1k2kOLu28P3JwHXu/uQFvuU0omSg+yZrFgaJ48fysnjg9y7ubKW\neR+UM2VsPgB/e3st1/3fO/RLT6VoxADGD89lwohcTpkwlKyYHosRSRbx/t9eCPwlfMI3DbjP3Z+M\ncwzSQl52jJlFHxfSzpw0gmG5mby6opy3V2/lgddWcdcrpZwc7nP//JW8s3YbRcNzKRqRy/6FOc1D\nfohI3xHX5ODuK4BDd7PPmPhEI+0JksUwZhYNA6Ch0VlZXkVORvBPZcXGSh5eUMbdr3wIQCwthSlj\n8vnTV44Eggf0cjLSGJWfRaqGlxVJWKonkF1KTTHGDspuXv7+pw7mmpkH8cGmShat3sqi1VtpOf3E\ndx9+i8VrthFLS2HfwTnsPySHo/ct4AtTRgNQ39BImkoaIr2ekoN0WUqKse/gHPYdnMMZk0bstO2n\nn5nA0nXbWb6+gmUfbef1lZsBmpPDUT/9N5npKYwpyGafgizGDsqmeEw+k0YNjPt9iEjHlBykW00c\nOZCJI3f+om8MixYNjc55R46mdFMlpZuq+Nvba9lSVcel08cyadRAdtQ28Mn/eY7R+VmMzs9i2MBM\nhuf2o3hMHuMG50RxOyJJS8lBelxK2PaQmmJ888QDdtq2paq2eVrUHXUNHDk2nw82VfKvpevZWFED\nwLWnHsK4wTm8v6GCz/z2ZYblZjJ8YL/m15PHF7LfkP7U1Dewo7aB3H7pGtZcZC8pOUikBmbFmt/n\nZ8f4n8/UP25gAAAOOElEQVRPal6uqW9g/bYassPG8Iy0FE4/dDhrt+5gzZZq3li5mc1Vdew7OJv9\nhvTntQ82c/7t84ilpVA4IIPC/pkMGZDB10/Yn4OGDmDt1h2891EFg3JiDM7JID87pvYPkQ4oOUiv\nlZGWutN4UCPzsrjhzKKd9tlR20BK+P2+T0EWP/z0wWzYXsNH26r5aFsN767bTl19UDJ5YdlGvjP3\nreZjzSAvK8b9s47igML+vPz+Rv61ZD2DcjIoyI6Rlx0jPzudohG5ZKSl9vwNi/QiSg6S0PrFPv7S\nHpWfxVemj+tw35MOKWTcZVPZWFHDhopaNm6vYWNFDQXZQenlvXXb+fP8lVTVNux03Gs/+CSD+6cy\n+5/LuOuVUvKy0snLCpJHXlY6N5xZREZaKm+s3My6rdXkZqUzsF+MvOzgtWWMIolCyUGSxsCsGMVj\n8jvcftG0sVw0bSxVtfWUV9ayubKO8qpa8rKC2faKRgzgUxOGBusra1lVXsXi1XXEwqqp++ev4oGS\nVTuds196KktumAnAfz+5lJLScgZkpjOgXzq5/dIZmpvJZTP2BWDhqi1U1zXQPzONAZnp9M9MIycj\nTVVfEgklB5FWsmJpZMXSGJm38/oTDi7khIMLOzzuu6ccxEXTxrClqo4tVbVs2VG30xhVORlppKWk\nsG5bNe9+tJ1tO+ooyMloTg7//cRSXlmxaadzHljYn39881gAvv7nN1hZXkX/zLTgJyOdg4b15+Jp\nYwH4x+J1NDR6uD2dnIw08rNj5GfHEOkqJQeRbrK7L+Irjt+PK47fb6d1LUdFvuHMItZvq2ZbdR3b\nq+vZXl1PTubH/0WH9M9gc1Ut26vrWbu1mu3VdWyqrG1ODjc8/g5lm3eeDfDEQwr5/ZeCATiP+9kz\nVNc1kpWRSnYsjeyMVI4/cAhfDZPTTU8sJZZqZGWkkR1LJSuWxoFD+1M0Ihd3Z+m67WTH0pqPz0xP\nUa+wPkzJQSRCLb9c9xuSw35DOn6e44enHrLLcz3w1als21FHRU0928MEMzgno3n7yUVD2VxZS2Vt\nA1U19VTWNlDXEJRs3J17X/2Q7TX1O53zy9PGUjQil+q6Rk6Z/UKr2OHqE/bnG588gM2VtXx+ziv0\ni6XRLz2FrFga/dJT+czhIzjh4EK2VNVy58ulZMVS6RdLIys9laxYKkUjchmVn0V1XQOrt+wgK5ZK\nZloq/WKpZKQp+URJyUGkjxgxsB8jdjEt7PdOObjDbWbG29edTGOjU13fQGVNA1W19c2N6akpxq3n\nHR4kltr65u2TwzYcB8YNymFHXfCsyYbtNVTV1rOpcjAAG7bX8Mt/Lmtz3Zs+M4EvTBnN0nXbOfM3\nL7XZ/usvHsapE4ez4MNyvvXQW2Smp5KZnkJmWvD6zRMPYOLIgbyzZhsPlqwio3lbkFw+PXEYhQMy\nWb1lB0vWbAvWh/tkpKcwOj+LzPRUausbaXQnlprS/FxOslNyEJFmKSnW3OYCH5c6YmkpnDJhWIfH\n5WfHuO2CIzrcvn9hf96/8VPsqAuSyo7aBqpqGygckAnA6PwsZn9hEpU1DVTXNVBd30B1XSMHFAbz\nkGTF0pgwIpcddcH2HbUNVNTUU9cQVMuVba7ikdfLqK5v3KmdZ9LogRQOyOSlZRv5zsNvtYnrH984\nlgOH9ufeeR9y3f+9E9xragoZaSlkpKfw2JXHMHxgPx54bSX3zV9FRloKmempwT7pKfz3ZyeSk5HG\nv5Z8xLwPyomlphBLC46PpaXwpaljSE0xFq3eStnmHcF5w22Z6UHJCWBrVR11jY3E0lKIpaaQnpoS\n+cCVSg4iEhepKUZORlrzCL8t5WfH2ozT1dLBwwbwq3MP63D7SeOH8lY4R0ljo1Pb0Eh1XUPzA5Qn\nHlLIY8OmUVMfrK+pa6SmvpHhA4PkdMQ+eXxn5oHU1jdSXddITX0DNfWNzcdnpqeS2y+dmroGtu2o\no7qugdqGRpq+vheu2sI9r3xITX3DTgNRXjh1DAD3zlvJn+ev3Cnmlj3Zrn1sEX9duGan7YUDMpj3\n/U8C8P8eXMgr728iPTWF848azaxj9+3wd9Fd4j5NaHfRNKEi0hvVNzRS29BITV0jeWEHhY+2VbOx\nooba+iAp1dY30uDO8QcG85y9uGwjKzZWUFsfHFtX72SkpzT3ZLvr5VIWrd5KXUMjnzi4kNMPHb7H\n8XV2mlAlBxGRJNJr55AWEZHeT8lBRETaUHIQEZE2lBxERKQNJQcREWkj7s85mFkpsB1oAOrdvdjM\nfgacBtQC7wMXu/uWeMcmIiKBqEoOx7v7pBbdqZ4Gitx9IvAe8L2I4hIREXpJtZK7P+XuTSN+vQqM\njDIeEZFkF8XwGQ48ZWYO/M7d57Ta/mXggfYONLNZwKxwscLM3m21yyBgY3cGG7G+dj/Q9+6pr90P\n9L176mv3A3t3T/t0Zqe4PyFtZsPdfY2ZDSGoTrrK3Z8Pt/0AKAY+43sQmJmVdObJv0TR1+4H+t49\n9bX7gb53T33tfiA+9xT3aiV3XxO+rgf+AkwBMLMLgVOB8/YkMYiISPeJa3Iws2wz69/0HjgJWGRm\nM4HvAqe7e1U8YxIRkbbi3eZQCPwlnN0pDbjP3Z80s+UEg8c/HW571d0v24Pzt26/SHR97X6g791T\nX7sf6Hv31NfuB+JwTwk7KquIiPScXtGVVUREehclBxERaaNPJAczm2lm75rZcjO7Jup4uoOZlZrZ\n22a20MwSblYjM/ujma03s0Ut1uWb2dNmtix8zYsyxq7q4J5+bGarw89poZl9KsoYu8LMRpnZM2a2\nxMwWm9nV4fqE/Jx2cT+J/Bllmtl8M3szvKfrwvVjzWxe+Bk9YGaxbr92orc5mFkqwZAbJwJlwGvA\nue7+TqSB7aVwDKpid0/Ih3fM7FigArjb3YvCdTcD5e5+U5jE89z9u1HG2RUd3NOPgQp3/3mUse0J\nMxsGDHP318NehAuAM4GLSMDPaRf38zkS9zMyINvdK8wsHXgRuBr4f8Aj7n6/md0GvOnut3bntftC\nyWEKsNzdV7h7LXA/cEbEMSW98MHG8larzwDuCt/fRfAfN2F0cE8Jy93Xuvvr4fvtwBJgBAn6Oe3i\nfhKWByrCxfTwx4FPAHPD9T3yGfWF5DACWNViuYwE/wcRahpmZEE4bEhfUOjuayH4jwwMiTie7nKl\nmb0VVjslRBVMa2Y2BjgMmEcf+Jxa3Q8k8GdkZqlmthBYTzCqxPvAlhbj0fXId15fSA7WzrrErisL\nTHP3w4FTgCvCKg3pfW4F9gUmAWuBX0QbTteZWQ7wMPANd98WdTx7q537SejPyN0b3H0SwYCkU4CD\n29utu6/bF5JDGTCqxfJIYE1EsXSbjoYZSXAfhfXCTfXD6yOOZ6+5+0fhf95G4Pck2OcU1mM/DNzr\n7o+EqxP2c2rvfhL9M2oSznHzLHAUMNDMmh5i7pHvvL6QHF4D9g9b72PAF4DHIo5pr3Q0zEi0UXWL\nx4ALw/cXAn+NMJZu0fQlGjqLBPqcwsbO24El7v4/LTYl5OfU0f0k+Gc02MwGhu/7AZ8kaEt5Bjg7\n3K1HPqOE760EEHZN+yWQCvzR3f8r4pD2ipmNIygtwMfDjCTUPZnZn4HjCIYW/gj4T+BR4EFgNLAS\nOMfdE6aBt4N7Oo6gusKBUuCrTfX1vZ2ZHQO8ALwNNIarv09QT59wn9Mu7udcEvczmkjQ4JxK8Mf8\ng+5+ffgdcT+QD7wBnO/uNd167b6QHEREpHv1hWolERHpZkoOIiLShpKDiIi0oeQgIiJtKDmIiEgb\nSg6SFMzsIjPzDn62RBjXnWZWFtX1RToS72lCRaJ2DsFT9S3Vt7ejSDJTcpBks9Ddl0cdhEhvp2ol\nkVCLqqdjzexRM6sws01m9ptw6IKW+w4zs7vNbKOZ1YQjfp7fzjnHmtk9ZrYu3G+Fmc1uZ7/DzOwF\nM6sKJ3C5rNX2oWZ2l5mtCc+z1sweN7OEGzFVEoNKDpJsUlsMWNakMRyUrcmfCIaP+C3BIG3XAtkE\nk+A0jXf1HJBHMDzDKuB84B4zy3L3OeF+Y4H5QBXBUBvLCAaJPKnV9QcA9xEMAXM9cDFwq5m96+7P\nhPvcA+wDfDu8XiFwApC1p78IkV1yd/3op8//EHyxewc/j7fa57ZWx/4AaAAOCJevDPc7rtV+/yQY\nwTQ1XL6bYOa44buI687wXMe3WJcBbATmtFhXAXw96t+jfpLnRyUHSTZn0bZBunVvpQdbLd8P/ISg\nFPEecCyw2t2fbbXfn4A7gEMIBn87iSDx7G445Sr/uISAu9eY2TKCge+avAZ8Oxx59N/AInfXwGjS\nY5QcJNks8t03SH/UwXLTbFv5BJPGtLauxXaAAtomovZsbmddDZDZYvnzBFVT3yGoflobzh38E9+5\nSkykW6hBWqStwg6WV4ev5cDQdo5rWrcpfN1IN03f6O7r3f0Kdx8BHERQHXUd8NXuOL9Ia0oOIm19\nrtXyFwjmB5gfLj8HjDSzaa32+yJBm8OScPkp4NRWk83sNXd/192/T1DiKOrOc4s0UbWSJJtJZjao\nnfUlLd5/ysx+RvDlPoWgOudud38v3H4ncDXwiJn9gKDq6DzgRIKJZBrC/f4T+DTwspndCCwnKEnM\ndPc23V47Yma5BI3d9wJLgTrgDILeUk919jwiXaHkIMnmoQ7WD27x/nzgP4DLgVqCeYe/1bTR3SvN\nbAZwM3AT0B94F7jA3f/UYr9SMzuSoDH7p+F+q+n6lI7VwOvApQTdWRvD653n7gkxhackHs0EJxIy\ns4sIehvt34lGa5E+TW0OIiLShpKDiIi0oWolERFpQyUHERFpQ8lBRETaUHIQEZE2lBxERKQNJQcR\nEWnj/wM+Mo7oyqvOYgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1aec73d2c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Plotting data/training model ---\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get loss function\n",
    "loss = history.history['loss']\n",
    "#loss=[0]+list(loss)\n",
    "#val_loss = history.history['val_acc']\n",
    "#val_loss=[0]+list(val_loss)\n",
    "\n",
    "# Setup grid for plotting\n",
    "epochs =range(1, len(loss)+1 )\n",
    "#epochs=[0]+list(epochs)\n",
    "# Plot\n",
    "plt.close(\"all\")\n",
    "#plt.plot(epochs, loss, 'b', label='Training')\n",
    "plt.plot(epochs, loss,'--',label=\"Pinao-midi\")\n",
    "\n",
    "plt.title('Pinao-midi',fontsize=18)\n",
    "plt.xlabel('Epochs',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.legend()\n",
    "plt.savefig(\"piano_loss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[66.08233048865887,\n",
       " 57.30102874387543,\n",
       " 55.7143480038861,\n",
       " 54.95490775463272,\n",
       " 54.49356100526595,\n",
       " 54.17682241014999,\n",
       " 53.944118980679995,\n",
       " 53.765479588468864,\n",
       " 53.624926712719294,\n",
       " 53.50843904801594,\n",
       " 53.40780961734924,\n",
       " 53.327191343393494,\n",
       " 53.255552294699086,\n",
       " 53.1911200606831,\n",
       " 53.135965657549946,\n",
       " 53.08487351315261,\n",
       " 53.03895027073222,\n",
       " 52.99786759073764,\n",
       " 52.95759618429869,\n",
       " 52.923247461753206,\n",
       " 52.88984928133357,\n",
       " 52.860632392204046,\n",
       " 52.82984114751596,\n",
       " 52.8036316271264,\n",
       " 52.77923655394474,\n",
       " 52.75587776017148,\n",
       " 52.73340821420453,\n",
       " 52.71275793775518,\n",
       " 52.69222426410422,\n",
       " 52.67460942719316]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Modelling using LSTM.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
