{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y7RvF99XkNUk"
   },
   "source": [
    "### Image classification\n",
    "\n",
    "we will use the fashion mnist data in this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PqCY2SOFkL4r",
    "outputId": "49afe722-204d-4968-f4b5-889ffa702b4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikhi\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import mnist, cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "sPCpoavLkSld"
   },
   "outputs": [],
   "source": [
    "# =============================\n",
    "#  Reshaping data\n",
    "# ============================\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28,1).astype('float32') / 255\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28,1).astype('float32') / 255\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Structure\n",
    "In this section, we build a deep CNN to classify the fashion mnist image. The model structure is as follow:\n",
    "#1 Convoluntional layer 1:\n",
    "  - 32 filter\n",
    "  - kernel_size=[3,3]\n",
    "  - stride=1\n",
    "  - no padding\n",
    "  - activation function: relu\n",
    "  \n",
    "#2 Convoluntional layer 2:\n",
    "  - 32 filter\n",
    "  - kernel_size=[3,3]\n",
    "  - stride=1\n",
    "  - no padding\n",
    "  - activation function: relu\n",
    " \n",
    "#3 MaxPooling Layer 1: \n",
    "  - pool_size=2\n",
    " \n",
    "#4 dropout\n",
    "\n",
    "#5 Fully connected layer with 64 hidden nodes\n",
    "  - activation function: ReLU\n",
    "\n",
    "#6 Fully connected layer to the output layer\n",
    "  - 10 outputs\n",
    "  - activation function: softmax\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sFrQtz4RkaYg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                294976    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 305,194\n",
      "Trainable params: 305,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x274b27a2588>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nV1bKAbSLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x274afd39278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 32,kernel_size=(3, 3), \n",
    "                 activation='relu', strides=(1, 1), \n",
    "                 padding='valid',\n",
    "                 input_shape=(28,28,1)))\n",
    "model.add(Conv2D(filters = 32,kernel_size=(3, 3), \n",
    "                 activation='relu', strides=(1, 1), \n",
    "                 padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "#model.add(Activation(tf.nn.softmax))\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_training = model.fit(X_train, Y_train,\n",
    "          epochs=15,\n",
    "          batch_size=128,\n",
    "         verbose = 0)\n",
    "\n",
    "plt.plot(model_training.history[\"acc\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IdCJ_gIGkfmP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 59s 989us/step\n",
      "10000/10000 [==============================] - 10s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =====================\n",
    "#  Evaluating the model\n",
    "# =====================\n",
    "score_train = model.evaluate(X_train, Y_train, verbose=1)\n",
    "score_test = model.evaluate(X_test, Y_test, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on the training set:  0.05678995476091901\n",
      "accuracy on the training set:  0.9809666666666667\n",
      "loss on the test set:  0.259400545167923\n",
      "accuracy on the test set:  0.9212\n"
     ]
    }
   ],
   "source": [
    "print(\"loss on the training set: \", score_train[0])\n",
    "print(\"accuracy on the training set: \", score_train[1])\n",
    "\n",
    "print(\"loss on the test set: \", score_test[0])\n",
    "print(\"accuracy on the test set: \", score_test[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TeRzz3BHkmuD"
   },
   "source": [
    "### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "EWoQVxhvklxD"
   },
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "1aATl5GYkvym"
   },
   "outputs": [],
   "source": [
    "path_train_data = \"mnist/train/\"\n",
    "X_train_resize=[]\n",
    "basewidth=48\n",
    "baseheight=48\n",
    "for i in range(60000):\n",
    "    img=Image.fromarray(X_train[i,:,:])\n",
    "    img = img.resize((basewidth,baseheight), Image.ANTIALIAS)\n",
    "    #img.save(path_train_data+str(i+1)+\".jpg\")\n",
    "    img_array=np.array(img)\n",
    "    #print(img_array.shape)\n",
    "    X_train_resize.append(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_train_data = \"mnist/test/\"\n",
    "X_test_resize=[]\n",
    "basewidth=48\n",
    "baseheight=48\n",
    "for i in range(10000):\n",
    "    img=Image.fromarray(X_test[i,:,:])\n",
    "    img = img.resize((basewidth,baseheight), Image.ANTIALIAS)\n",
    "    #img.save(path_train_data+str(i+1)+\".jpg\")\n",
    "    img_array=np.array(img)\n",
    "    #print(img_array.shape)\n",
    "    X_test_resize.append(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 48, 48)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_train_resize).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "HUQq4k2olFID"
   },
   "outputs": [],
   "source": [
    "X_train=np.repeat(np.array(X_train_resize)[:,:,:,np.newaxis],3,axis=3)/255\n",
    "X_test=np.repeat(np.array(X_test_resize)[:,:,:,np.newaxis],3,axis=3)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 48, 48, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jy6Ob_1wlIAA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 1, 1, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 14,848,586\n",
      "Trainable params: 14,848,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base =VGG16(weights=\"imagenet\",include_top=False,input_shape=(48,48,3))\n",
    "#conv_base=keras.applications.mobilenet.MobileNet(input_shape=(32,32,3),include_top=False, weights='imagenet')\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.summary()\n",
    "model.trainable_weights\n",
    "conv_base.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "1wC19QqZlMYH"
   },
   "outputs": [],
   "source": [
    "model.trainable_weights\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=RMSprop(1e-4),metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=False)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "200/200 [==============================] - 156s 780ms/step - loss: 1.6931 - acc: 0.5344\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 155s 775ms/step - loss: 1.0438 - acc: 0.7194\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 154s 768ms/step - loss: 0.8363 - acc: 0.7395\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 151s 756ms/step - loss: 0.7461 - acc: 0.7502\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 151s 757ms/step - loss: 0.7151 - acc: 0.7566\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 155s 775ms/step - loss: 0.6644 - acc: 0.7728\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 157s 784ms/step - loss: 0.6467 - acc: 0.7728\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 158s 792ms/step - loss: 0.6463 - acc: 0.7678\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 157s 785ms/step - loss: 0.5891 - acc: 0.7920\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 156s 782ms/step - loss: 0.5886 - acc: 0.7906\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 157s 786ms/step - loss: 0.5814 - acc: 0.7934\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 156s 779ms/step - loss: 0.5804 - acc: 0.7939\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 155s 773ms/step - loss: 0.5630 - acc: 0.7970\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 158s 792ms/step - loss: 0.5745 - acc: 0.7930\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 157s 783ms/step - loss: 0.5678 - acc: 0.8000\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 156s 778ms/step - loss: 0.5376 - acc: 0.8108\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 154s 771ms/step - loss: 0.5456 - acc: 0.8048\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 154s 772ms/step - loss: 0.5163 - acc: 0.8208\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 152s 760ms/step - loss: 0.5236 - acc: 0.8163\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 153s 763ms/step - loss: 0.5243 - acc: 0.8158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17030cbaeb8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fits the model on batches with real-time data augmentation:\n",
    "model.fit_generator(datagen.flow(X_train, Y_train, batch_size=32),\n",
    "                    steps_per_epoch=200, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 386s 39ms/step\n"
     ]
    }
   ],
   "source": [
    "result=model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy on test data is: 0.826\n"
     ]
    }
   ],
   "source": [
    "print(\" accuracy on test data is: \"+ str(result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "anly590_hw2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
